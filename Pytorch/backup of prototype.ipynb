{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "735\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "path = \"./../dist/char*.txt\"\n",
    "contents=[]\n",
    "for filename in glob.glob(path):\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            contents.append(line.strip('\\n'))\n",
    "print(len(contents))\n",
    "i=0\n",
    "while (i<len(contents)-1):\n",
    "    contents[i]=float(contents[i])\n",
    "    i+=1\n",
    "    if ((i+1)%15==0):\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint as r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  :  tensor([2.0500e+02, 2.1200e+02, 1.3217e+02, 1.3670e+02, 4.9991e+00, 4.9991e+00,\n",
      "        1.7822e+01, 1.7248e+01, 9.8096e+04, 7.5926e+03, 9.8987e+00, 7.6623e-01,\n",
      "        4.7512e-02, 4.5995e-02])\n",
      "1  :  tensor([2.0800e+02, 2.1700e+02, 1.3411e+02, 1.3994e+02, 5.2510e+00, 5.3857e+00,\n",
      "        1.7077e+01, 1.6586e+01, 9.8127e+04, 5.0104e+03, 9.8719e+00, 5.0406e-01,\n",
      "        4.6135e-02, 4.5194e-02])\n",
      "2  :  tensor([2.0400e+02, 2.1600e+02, 1.3152e+02, 1.3929e+02, 4.9991e+00, 5.4781e+00,\n",
      "        1.5611e+01, 1.7447e+01, 9.8457e+04, 4.5087e+03, 9.9241e+00, 4.5447e-01,\n",
      "        4.7951e-02, 4.5417e-02])\n",
      "3  :  tensor([2.2700e+02, 2.3700e+02, 1.4642e+02, 1.5290e+02, 5.2765e+00, 4.9991e+00,\n",
      "        1.6634e+01, 1.6126e+01, 9.8448e+04, 4.2835e+03, 9.9082e+00, 4.3106e-01,\n",
      "        4.3383e-02, 4.1325e-02])\n",
      "4  :  tensor([2.2600e+02, 2.0600e+02, 1.4577e+02, 1.3282e+02, 5.4436e+00, 5.4841e+00,\n",
      "        1.7649e+01, 1.6586e+01, 9.8765e+04, 7.1877e+03, 9.9441e+00, 7.2369e-01,\n",
      "        4.3717e-02, 4.7825e-02])\n",
      "5  :  tensor([2.1600e+02, 2.1600e+02, 1.3929e+02, 1.3929e+02, 5.2510e+00, 5.5659e+00,\n",
      "        1.5803e+01, 1.7705e+01, 9.7870e+04, 5.5116e+03, 9.8809e+00, 5.5645e-01,\n",
      "        4.5593e-02, 4.5602e-02])\n",
      "6  :  tensor([2.0100e+02, 2.3100e+02, 1.2957e+02, 1.4901e+02, 5.1840e+00, 5.2510e+00,\n",
      "        1.6634e+01, 1.7077e+01, 9.7340e+04, 5.9237e+03, 9.8076e+00, 5.9685e-01,\n",
      "        4.8776e-02, 4.2610e-02])\n",
      "7  :  tensor([2.1400e+02, 2.1600e+02, 1.3800e+02, 1.3929e+02, 5.3406e+00, 5.1840e+00,\n",
      "        1.6069e+01, 1.7248e+01, 9.8379e+04, 6.2308e+03, 9.9162e+00, 6.2804e-01,\n",
      "        4.6009e-02, 4.5347e-02])\n",
      "8  :  tensor([2.8200e+02, 2.4500e+02, 1.8205e+02, 1.5808e+02, 5.1840e+00, 5.2288e+00,\n",
      "        1.6634e+01, 1.5632e+01, 9.8374e+04, 5.8761e+03, 9.8938e+00, 5.9098e-01,\n",
      "        3.4929e-02, 4.0024e-02])\n",
      "9  :  tensor([2.1000e+02, 1.8300e+02, 1.3640e+02, 1.1878e+02, 7.7158e+00, 7.7407e+00,\n",
      "        1.3331e+01, 1.3311e+01, 3.9535e+04, 1.8109e+03, 9.9061e+00, 4.5386e-01,\n",
      "        1.8795e-02, 2.1579e-02])\n",
      "10  :  tensor([1.5400e+02, 2.2000e+02, 9.9851e+01, 1.4293e+02, 7.7443e+00, 7.7393e+00,\n",
      "        1.3120e+01, 1.3070e+01, 3.9687e+04, 1.3209e+03, 9.8748e+00, 3.2865e-01,\n",
      "        2.5143e-02, 1.7823e-02])\n",
      "11  :  tensor([1.7500e+02, 3.0100e+02, 1.1356e+02, 1.9579e+02, 7.7320e+00, 7.7502e+00,\n",
      "        1.3331e+01, 1.3087e+01, 3.9683e+04, 1.2161e+03, 9.8936e+00, 3.0319e-01,\n",
      "        2.2560e-02, 1.3252e-02])\n",
      "12  :  tensor([1.9300e+02, 2.5300e+02, 1.2530e+02, 1.6446e+02, 7.7683e+00, 7.8009e+00,\n",
      "        1.3040e+01, 1.2551e+01, 3.9517e+04, 3.6856e+03, 9.8989e+00, 9.2325e-01,\n",
      "        2.0368e-02, 1.5609e-02])\n",
      "13  :  tensor([2.0800e+02, 3.1400e+02, 1.3509e+02, 2.0427e+02, 7.7443e+00, 7.7158e+00,\n",
      "        1.3010e+01, 1.3041e+01, 3.9581e+04, 1.2183e+03, 9.8977e+00, 3.0305e-01,\n",
      "        1.8990e-02, 1.2576e-02])\n",
      "14  :  tensor([1.3000e+02, 2.3700e+02, 8.4188e+01, 1.5402e+02, 7.9499e+00, 7.7158e+00,\n",
      "        1.2962e+01, 1.2794e+01, 3.9233e+04, 1.3025e+03, 9.8377e+00, 3.2661e-01,\n",
      "        2.9869e-02, 1.6650e-02])\n",
      "15  :  tensor([1.3700e+02, 2.7700e+02, 8.8756e+01, 1.8013e+02, 7.7955e+00, 7.7204e+00,\n",
      "        1.3120e+01, 1.3072e+01, 3.9766e+04, 1.2035e+03, 9.8455e+00, 2.9796e-01,\n",
      "        2.7912e-02, 1.4256e-02])\n",
      "16  :  tensor([1.5500e+02, 2.3900e+02, 1.0050e+02, 1.5533e+02, 7.7393e+00, 7.7427e+00,\n",
      "        1.3087e+01, 1.3331e+01, 3.9319e+04, 1.2841e+03, 9.8916e+00, 3.2304e-01,\n",
      "        2.5729e-02, 1.6205e-02])\n",
      "17  :  tensor([1.2300e+02, 2.2000e+02, 7.9620e+01, 1.4293e+02, 7.7419e+00, 7.7280e+00,\n",
      "        1.2730e+01, 1.3107e+01, 3.9746e+04, 1.3701e+03, 9.9217e+00, 3.4201e-01,\n",
      "        3.1756e-02, 1.8014e-02])\n",
      "18  :  tensor([1.3200e+02, 2.2300e+02, 8.5493e+01, 1.4488e+02, 7.7427e+00, 7.7158e+00,\n",
      "        1.2867e+01, 1.3084e+01, 3.9436e+04, 1.3974e+03, 9.8615e+00, 3.4945e-01,\n",
      "        2.9318e-02, 1.7516e-02])\n",
      "19  :  tensor([1.7100e+02, 2.5900e+02, 1.1095e+02, 1.6838e+02, 7.8335e+00, 7.8095e+00,\n",
      "        1.3266e+01, 1.3116e+01, 3.9639e+04, 1.3465e+03, 9.9097e+00, 3.3663e-01,\n",
      "        2.3129e-02, 1.5351e-02])\n",
      "20  :  tensor([1.3900e+02, 2.4600e+02, 9.0062e+01, 1.5989e+02, 7.7683e+00, 7.7551e+00,\n",
      "        1.2555e+01, 1.3120e+01, 3.9856e+04, 1.2786e+03, 9.9366e+00, 3.1878e-01,\n",
      "        2.7281e-02, 1.6049e-02])\n",
      "21  :  tensor([1.6800e+02, 2.4300e+02, 1.0899e+02, 1.5794e+02, 7.7443e+00, 7.7419e+00,\n",
      "        1.3306e+01, 1.3107e+01, 3.9452e+04, 1.4540e+03, 9.9075e+00, 3.6515e-01,\n",
      "        2.3458e-02, 1.6309e-02])\n",
      "22  :  tensor([1.4900e+02, 2.5700e+02, 9.6588e+01, 1.6707e+02, 7.7427e+00, 7.7551e+00,\n",
      "        1.3306e+01, 1.2816e+01, 3.9448e+04, 1.3907e+03, 9.8398e+00, 3.4689e-01,\n",
      "        2.5980e-02, 1.5315e-02])\n",
      "23  :  tensor([1.4900e+02, 2.5600e+02, 9.6588e+01, 1.6642e+02, 7.7646e+00, 7.8969e+00,\n",
      "        1.2962e+01, 1.3306e+01, 3.9522e+04, 1.4244e+03, 9.9302e+00, 3.5788e-01,\n",
      "        2.6544e-02, 1.5109e-02])\n",
      "24  :  tensor([1.7800e+02, 2.7600e+02, 1.1551e+02, 1.7947e+02, 8.0189e+00, 7.7427e+00,\n",
      "        1.3115e+01, 1.3041e+01, 3.9658e+04, 1.0462e+03, 9.8996e+00, 2.6109e-01,\n",
      "        2.1904e-02, 1.4366e-02])\n",
      "25  :  tensor([1.3400e+02, 2.8200e+02, 8.6799e+01, 1.8339e+02, 7.7796e+00, 7.7427e+00,\n",
      "        1.3009e+01, 1.3162e+01, 3.9298e+04, 1.0546e+03, 9.8590e+00, 2.6456e-01,\n",
      "        2.9254e-02, 1.4092e-02])\n",
      "26  :  tensor([1.7800e+02, 3.1900e+02, 1.1551e+02, 2.0754e+02, 7.7443e+00, 7.7158e+00,\n",
      "        1.3084e+01, 1.3009e+01, 3.9488e+04, 9.2509e+02, 9.8993e+00, 2.3191e-01,\n",
      "        2.2017e-02, 1.2288e-02])\n",
      "27  :  tensor([2.2600e+02, 2.9400e+02, 1.4684e+02, 1.9122e+02, 7.7158e+00, 7.7705e+00,\n",
      "        1.3162e+01, 1.3266e+01, 3.9556e+04, 1.0364e+03, 9.7960e+00, 2.5667e-01,\n",
      "        1.7350e-02, 1.3486e-02])\n",
      "28  :  tensor([1.7700e+02, 2.2800e+02, 1.1486e+02, 1.4815e+02, 7.7480e+00, 7.7320e+00,\n",
      "        1.3237e+01, 1.3009e+01, 3.9501e+04, 1.1424e+03, 9.8729e+00, 2.8560e-01,\n",
      "        2.2390e-02, 1.7390e-02])\n",
      "29  :  tensor([1.8700e+02, 2.7400e+02, 1.2139e+02, 1.7817e+02, 7.7705e+00, 7.7443e+00,\n",
      "        1.2957e+01, 1.3084e+01, 3.9234e+04, 1.1389e+03, 9.8826e+00, 2.8687e-01,\n",
      "        2.1037e-02, 1.4460e-02])\n",
      "30  :  tensor([1.4800e+02, 2.6800e+02, 9.5935e+01, 1.7425e+02, 7.7443e+00, 7.7280e+00,\n",
      "        1.2794e+01, 1.3306e+01, 3.9467e+04, 1.1817e+03, 9.8668e+00, 2.9542e-01,\n",
      "        2.6946e-02, 1.4731e-02])\n",
      "31  :  tensor([1.4300e+02, 1.8000e+02, 5.7745e+01, 7.2791e+01, 5.2732e+00, 5.4549e+00,\n",
      "        1.5429e+01, 1.5197e+01, 7.9757e+04, 4.8122e+03, 9.9759e+00, 6.0190e-01,\n",
      "        5.5343e-02, 4.3933e-02])\n",
      "32  :  tensor([1.3600e+02, 2.0300e+02, 5.4899e+01, 8.2144e+01, 5.6409e+00, 5.5057e+00,\n",
      "        1.5429e+01, 1.5329e+01, 7.9357e+04, 4.9368e+03, 9.9159e+00, 6.1687e-01,\n",
      "        5.8199e-02, 3.8616e-02])\n",
      "33  :  tensor([1.5300e+02, 1.7500e+02, 6.1812e+01, 7.0758e+01, 5.7200e+00, 5.3068e+00,\n",
      "        1.5320e+01, 1.5251e+01, 7.8484e+04, 4.5058e+03, 9.7580e+00, 5.6022e-01,\n",
      "        5.2046e-02, 4.5234e-02])\n",
      "34  :  tensor([1.4000e+02, 1.9100e+02, 5.6525e+01, 7.7265e+01, 6.0021e+00, 5.4710e+00,\n",
      "        1.5106e+01, 1.4970e+01, 7.9453e+04, 3.9024e+03, 9.8786e+00, 4.8520e-01,\n",
      "        5.6129e-02, 4.1691e-02])\n",
      "35  :  tensor([1.0800e+02, 1.7500e+02, 4.3512e+01, 7.0758e+01, 5.7349e+00, 5.3194e+00,\n",
      "        1.5251e+01, 1.5329e+01, 7.8568e+04, 3.6989e+03, 9.7868e+00, 4.6074e-01,\n",
      "        7.1426e-02, 4.5229e-02])\n",
      "36  :  tensor([1.1700e+02, 1.5200e+02, 4.7172e+01, 6.1405e+01, 5.6005e+00, 5.3068e+00,\n",
      "        1.5303e+01, 1.5320e+01, 7.9762e+04, 5.9233e+03, 9.9579e+00, 7.3949e-01,\n",
      "        6.5932e-02, 5.2072e-02])\n",
      "37  :  tensor([1.3300e+02, 1.8700e+02, 5.3679e+01, 7.5638e+01, 5.5203e+00, 5.2732e+00,\n",
      "        1.5175e+01, 1.5251e+01, 7.9165e+04, 3.2447e+03, 9.8746e+00, 4.0473e-01,\n",
      "        5.9504e-02, 4.2326e-02])\n",
      "38  :  tensor([1.3200e+02, 1.8700e+02, 5.3272e+01, 7.5638e+01, 5.6005e+00, 5.5047e+00,\n",
      "        1.5228e+01, 1.4685e+01, 7.8644e+04, 2.6093e+03, 9.7852e+00, 3.2465e-01,\n",
      "        5.9955e-02, 4.2588e-02])\n",
      "39  :  tensor([1.3000e+02, 1.8300e+02, 5.2459e+01, 7.4011e+01, 5.4549e+00, 5.5292e+00,\n",
      "        1.5322e+01, 1.5318e+01, 7.9846e+04, 2.5762e+03, 9.9533e+00, 3.2114e-01,\n",
      "        6.0877e-02, 4.3257e-02])\n",
      "40  :  tensor([1.4600e+02, 2.0500e+02, 5.8965e+01, 8.2958e+01, 5.6553e+00, 5.4192e+00,\n",
      "        1.5258e+01, 1.5322e+01, 7.8997e+04, 3.0596e+03, 9.8121e+00, 3.8002e-01,\n",
      "        5.4548e-02, 3.8610e-02])\n",
      "41  :  tensor([1.1900e+02, 1.9300e+02, 4.7985e+01, 7.8078e+01, 5.6005e+00, 5.3978e+00,\n",
      "        1.5426e+01, 1.5322e+01, 7.8849e+04, 3.7705e+03, 9.8328e+00, 4.7019e-01,\n",
      "        6.4042e-02, 4.1005e-02])\n",
      "42  :  tensor([1.3300e+02, 1.7600e+02, 5.3679e+01, 7.1165e+01, 5.6244e+00, 5.3194e+00,\n",
      "        1.5228e+01, 1.5258e+01, 7.9815e+04, 4.2108e+03, 9.8965e+00, 5.2210e-01,\n",
      "        5.9887e-02, 4.4966e-02])\n",
      "43  :  tensor([1.3700e+02, 1.5900e+02, 5.5305e+01, 6.4252e+01, 5.4490e+00, 5.5309e+00,\n",
      "        1.5251e+01, 1.5045e+01, 8.0175e+04, 6.6013e+03, 9.9944e+00, 8.2289e-01,\n",
      "        5.7774e-02, 4.9774e-02])\n",
      "44  :  tensor([1.3300e+02, 1.8900e+02, 5.3679e+01, 7.6451e+01, 5.6005e+00, 5.4049e+00,\n",
      "        1.5131e+01, 1.5318e+01, 7.8935e+04, 3.9692e+03, 9.8966e+00, 4.9764e-01,\n",
      "        5.7917e-02, 4.1884e-02])\n",
      "45  :  tensor([1.2900e+02, 1.7800e+02, 5.2052e+01, 7.1978e+01, 5.4561e+00, 5.5057e+00,\n",
      "        1.5342e+01, 1.5228e+01, 7.9794e+04, 4.1312e+03, 9.9320e+00, 5.1422e-01,\n",
      "        6.0302e-02, 4.4466e-02])\n",
      "46  :  tensor([1.4100e+02, 1.8400e+02, 5.6932e+01, 7.4418e+01, 5.3978e+00, 5.3068e+00,\n",
      "        1.5320e+01, 1.5426e+01, 7.9195e+04, 3.1444e+03, 9.8846e+00, 3.9246e-01,\n",
      "        5.4191e-02, 4.3277e-02])\n",
      "47  :  tensor([1.3600e+02, 1.9500e+02, 5.4899e+01, 7.8891e+01, 5.4710e+00, 5.4049e+00,\n",
      "        1.5426e+01, 1.5082e+01, 7.8355e+04, 3.2731e+03, 9.7663e+00, 4.0796e-01,\n",
      "        5.7228e-02, 4.0585e-02])\n",
      "48  :  tensor([1.6800e+02, 1.6700e+02, 6.7911e+01, 6.7505e+01, 5.5047e+00, 5.7200e+00,\n",
      "        1.5175e+01, 1.5291e+01, 7.9404e+04, 5.7379e+03, 9.9442e+00, 7.1858e-01,\n",
      "        4.7113e-02, 4.7054e-02])\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for a in range(0, 49):\n",
    "    i=r(0, (len(contents)/15-1))\n",
    "    tt=torch.tensor(contents[(a*15):(a*15+14)])\n",
    "    print(a, ' : ', tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=14, out_features=14, bias=True)\n",
    "        self.fc2 = nn.Linear(in_features=14, out_features=14, bias=True)\n",
    "        self.out = nn.Linear(in_features=14, out_features = 4, bias=True)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        #1st layer\n",
    "        t = self.fc1(t)\n",
    "        #2nd layer\n",
    "        t = self.fc2(t)\n",
    "        #output layer\n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0 loss:  tensor(26808414., grad_fn=<MseLossBackward>)\n",
      "iteration:  1000 loss:  tensor(1788.8007, grad_fn=<MseLossBackward>)\n",
      "iteration:  2000 loss:  tensor(365.0630, grad_fn=<MseLossBackward>)\n",
      "iteration:  3000 loss:  tensor(145.4761, grad_fn=<MseLossBackward>)\n",
      "iteration:  4000 loss:  tensor(386.8251, grad_fn=<MseLossBackward>)\n",
      "iteration:  5000 loss:  tensor(305.6943, grad_fn=<MseLossBackward>)\n",
      "iteration:  6000 loss:  tensor(1516.2721, grad_fn=<MseLossBackward>)\n",
      "iteration:  7000 loss:  tensor(287.8032, grad_fn=<MseLossBackward>)\n",
      "iteration:  8000 loss:  tensor(589.1656, grad_fn=<MseLossBackward>)\n",
      "iteration:  9000 loss:  tensor(725.9103, grad_fn=<MseLossBackward>)\n",
      "iteration:  10000 loss:  tensor(570.1378, grad_fn=<MseLossBackward>)\n",
      "iteration:  11000 loss:  tensor(111.2339, grad_fn=<MseLossBackward>)\n",
      "iteration:  12000 loss:  tensor(422.8947, grad_fn=<MseLossBackward>)\n",
      "iteration:  13000 loss:  tensor(831.4242, grad_fn=<MseLossBackward>)\n",
      "iteration:  14000 loss:  tensor(767.6873, grad_fn=<MseLossBackward>)\n",
      "iteration:  15000 loss:  tensor(191.7307, grad_fn=<MseLossBackward>)\n",
      "iteration:  16000 loss:  tensor(399.2169, grad_fn=<MseLossBackward>)\n",
      "iteration:  17000 loss:  tensor(21.6875, grad_fn=<MseLossBackward>)\n",
      "iteration:  18000 loss:  tensor(198.9815, grad_fn=<MseLossBackward>)\n",
      "iteration:  19000 loss:  tensor(130.0108, grad_fn=<MseLossBackward>)\n",
      "iteration:  20000 loss:  tensor(5.4697, grad_fn=<MseLossBackward>)\n",
      "iteration:  21000 loss:  tensor(1477.2349, grad_fn=<MseLossBackward>)\n",
      "iteration:  22000 loss:  tensor(70.2330, grad_fn=<MseLossBackward>)\n",
      "iteration:  23000 loss:  tensor(123.2824, grad_fn=<MseLossBackward>)\n",
      "iteration:  24000 loss:  tensor(1409.9288, grad_fn=<MseLossBackward>)\n",
      "iteration:  25000 loss:  tensor(71.7428, grad_fn=<MseLossBackward>)\n",
      "iteration:  26000 loss:  tensor(164.6629, grad_fn=<MseLossBackward>)\n",
      "iteration:  27000 loss:  tensor(61.9164, grad_fn=<MseLossBackward>)\n",
      "iteration:  28000 loss:  tensor(122.8858, grad_fn=<MseLossBackward>)\n",
      "iteration:  29000 loss:  tensor(30.3595, grad_fn=<MseLossBackward>)\n",
      "iteration:  30000 loss:  tensor(87.8995, grad_fn=<MseLossBackward>)\n",
      "iteration:  31000 loss:  tensor(119.8805, grad_fn=<MseLossBackward>)\n",
      "iteration:  32000 loss:  tensor(178.8776, grad_fn=<MseLossBackward>)\n",
      "iteration:  33000 loss:  tensor(438.5491, grad_fn=<MseLossBackward>)\n",
      "iteration:  34000 loss:  tensor(21.9142, grad_fn=<MseLossBackward>)\n",
      "iteration:  35000 loss:  tensor(88.8818, grad_fn=<MseLossBackward>)\n",
      "iteration:  36000 loss:  tensor(33.1349, grad_fn=<MseLossBackward>)\n",
      "iteration:  37000 loss:  tensor(2.0240, grad_fn=<MseLossBackward>)\n",
      "iteration:  38000 loss:  tensor(118.5180, grad_fn=<MseLossBackward>)\n",
      "iteration:  39000 loss:  tensor(56.1380, grad_fn=<MseLossBackward>)\n",
      "iteration:  40000 loss:  tensor(89.0262, grad_fn=<MseLossBackward>)\n",
      "iteration:  41000 loss:  tensor(41.6677, grad_fn=<MseLossBackward>)\n",
      "iteration:  42000 loss:  tensor(107.4712, grad_fn=<MseLossBackward>)\n",
      "iteration:  43000 loss:  tensor(115.9509, grad_fn=<MseLossBackward>)\n",
      "iteration:  44000 loss:  tensor(184.0851, grad_fn=<MseLossBackward>)\n",
      "iteration:  45000 loss:  tensor(6.0870, grad_fn=<MseLossBackward>)\n",
      "iteration:  46000 loss:  tensor(139.5531, grad_fn=<MseLossBackward>)\n",
      "iteration:  47000 loss:  tensor(2.5406, grad_fn=<MseLossBackward>)\n",
      "iteration:  48000 loss:  tensor(212.5063, grad_fn=<MseLossBackward>)\n",
      "iteration:  49000 loss:  tensor(52.9455, grad_fn=<MseLossBackward>)\n",
      "iteration:  50000 loss:  tensor(347.5254, grad_fn=<MseLossBackward>)\n",
      "iteration:  51000 loss:  tensor(28.1762, grad_fn=<MseLossBackward>)\n",
      "iteration:  52000 loss:  tensor(101.0058, grad_fn=<MseLossBackward>)\n",
      "iteration:  53000 loss:  tensor(149.7949, grad_fn=<MseLossBackward>)\n",
      "iteration:  54000 loss:  tensor(21.4096, grad_fn=<MseLossBackward>)\n",
      "iteration:  55000 loss:  tensor(114.4344, grad_fn=<MseLossBackward>)\n",
      "iteration:  56000 loss:  tensor(24.5790, grad_fn=<MseLossBackward>)\n",
      "iteration:  57000 loss:  tensor(28.9053, grad_fn=<MseLossBackward>)\n",
      "iteration:  58000 loss:  tensor(5.9752, grad_fn=<MseLossBackward>)\n",
      "iteration:  59000 loss:  tensor(52.9871, grad_fn=<MseLossBackward>)\n",
      "iteration:  60000 loss:  tensor(68.8946, grad_fn=<MseLossBackward>)\n",
      "iteration:  61000 loss:  tensor(109.1503, grad_fn=<MseLossBackward>)\n",
      "iteration:  62000 loss:  tensor(3.3065, grad_fn=<MseLossBackward>)\n",
      "iteration:  63000 loss:  tensor(58.2196, grad_fn=<MseLossBackward>)\n",
      "iteration:  64000 loss:  tensor(10.8101, grad_fn=<MseLossBackward>)\n",
      "iteration:  65000 loss:  tensor(44.3179, grad_fn=<MseLossBackward>)\n",
      "iteration:  66000 loss:  tensor(50.1417, grad_fn=<MseLossBackward>)\n",
      "iteration:  67000 loss:  tensor(7.4010, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "net=Network()\n",
    "params=list(net.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "net.zero_grad()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0000000005)\n",
    "loss = 4\n",
    "i=0\n",
    "while (loss > 0.01):\n",
    "    a=r(0, (len(contents)/15-1))\n",
    "    chars = torch.tensor(contents[(a*15):(a*15+14)])\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    out = net(chars)\n",
    "    if (contents[a*14+15]=='Marcin'):\n",
    "        target = torch.tensor([1., 0., 0., 0.])\n",
    "    elif (contents[a*14+15]=='Bartek'):\n",
    "        target = torch.tensor([0., 1., 0., 0.])\n",
    "    elif (contents[a*14+15]=='Maciek'):\n",
    "        target = torch.tensor([0., 0., 1., 0.,])\n",
    "    else:\n",
    "        target = torch.tensor([0., 0., 0., 1.,])\n",
    "    loss = criterion(out, target)\n",
    "    loss.backward(retain_graph=True)\n",
    "    #loss.backward()\n",
    "    optimizer.step()    # Does the update\n",
    "    if i%1000==0:\n",
    "        print(\"iteration: \", i, \"loss: \", loss)\n",
    "    i+=1\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, \"net.dat\")\n",
    "torch.save(net.state_dict(), \"netstate.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haba = torch.load(\"net.dat\")\n",
    "baba = Network()\n",
    "baba.load_state_dict(torch.load(\"netstate.dat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
