{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba plików:  125.0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "path = \"./../dist/char*.txt\"\n",
    "contents=[]\n",
    "for filename in glob.glob(path):\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            contents.append(line.strip('\\n'))\n",
    "print('Liczba plików: ', len(contents)/15)\n",
    "i=0\n",
    "while (i<len(contents)-1):\n",
    "    contents[i]=float(contents[i])\n",
    "    i+=1\n",
    "    if ((i+1)%15==0):\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint as r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     a=r(0, (len(contents)/15))\n",
    "#     print(a)\n",
    "#     print(torch.tensor(contents[(a*15):(a*15+14)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=14, out_features=14)\n",
    "        self.fc2 = nn.Linear(in_features=14, out_features=4)\n",
    "        #self.out = nn.Linear(in_features=14, out_features = 4, bias=True)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        #1st layer\n",
    "        t = self.fc1(t)\n",
    "        #2nd layer\n",
    "        t = self.fc2(t)\n",
    "\n",
    "        #t = F.softmax(t)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Network()\n",
    "params=list(net.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "net.zero_grad()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.000000001)\n",
    "lossDuplicationCounter = 0\n",
    "prevloss=5\n",
    "loss = 4\n",
    "i=0\n",
    "good = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iteration:  0 \n",
      "Loss:  1.1125e+08 \n",
      "Output:  [ -3610.8003, -15048.6631, -14250.2402,   1565.6216],\n",
      " \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  1000 \n",
      "Loss:  168995.4688 \n",
      "Output:  [-193.9147, -359.6286, -674.1716, -230.6286] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  2000 \n",
      "Loss:  7035.9116 \n",
      "Output:  [-13.2299, 122.7658,  72.7841,  88.1760] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  3000 \n",
      "Loss:  41.1001 \n",
      "Output:  [ 0.5807, 10.0269, -2.0258,  8.8586] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  4000 \n",
      "Loss:  2240.0986 \n",
      "Output:  [-17.7138, -39.1847, -84.1103,  -0.4564] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  5000 \n",
      "Loss:  937.6060 \n",
      "Output:  [-18.1604,  26.4323,  14.0634, -49.2412] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  6000 \n",
      "Loss:  36.1628 \n",
      "Output:  [ 9.7607, -5.7863,  3.9377,  0.3722] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  7000 \n",
      "Loss:  37.0070 \n",
      "Output:  [ 1.6326,  2.3806,  3.7165, 12.2198] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  8000 \n",
      "Loss:  44.4864 \n",
      "Output:  [-4.7857,  7.0916, -2.1375, -9.7421] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  9000 \n",
      "Loss:  58.5813 \n",
      "Output:  [ 2.2763, -7.1546, -1.1308, 13.1687] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  10000 \n",
      "Loss:  7.5658 \n",
      "Output:  [ 3.4793, -0.6184,  4.0746,  2.0831] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  11000 \n",
      "Loss:  344.9772 \n",
      "Output:  [  6.5671, -11.3649,  -5.0998,  34.0277] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  12000 \n",
      "Loss:  463.3817 \n",
      "Output:  [  0.0651,  18.7492,  18.2350, -34.7123] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  13000 \n",
      "Loss:  4.8235 \n",
      "Output:  [ 2.8846, -0.2842,  3.1039, -0.1218] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  14000 \n",
      "Loss:  231.9066 \n",
      "Output:  [-1.1190,  0.7616, -6.3779, 29.7597] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  15000 \n",
      "Loss:  9.1330 \n",
      "Output:  [ 2.8341, -1.2039,  4.6141, -3.7402] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  16000 \n",
      "Loss:  182.5227 \n",
      "Output:  [ 2.2492, -6.5600, -5.5039, 25.2505] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  17000 \n",
      "Loss:  6.1698 \n",
      "Output:  [-0.3530, -3.3330,  0.0107,  3.5308] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  18000 \n",
      "Loss:  0.7187 \n",
      "Output:  [-0.2255, -1.0797, -0.1315,  2.2809] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  19000 \n",
      "Loss:  77.0756 \n",
      "Output:  [-9.4496, 12.1932, -1.2595, -8.0764] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  20000 \n",
      "Loss:  1.7268 \n",
      "Output:  [ 1.2322, -2.1670,  0.7549,  1.3508] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  21000 \n",
      "Loss:  93.7027 \n",
      "Output:  [-0.9726, -1.9431, -3.2429, 18.8331] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  22000 \n",
      "Loss:  21.1199 \n",
      "Output:  [-2.3580,  2.0383, -3.7879,  7.9682] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  23000 \n",
      "Loss:  9.7099 \n",
      "Output:  [ 4.0477, -3.3147,  2.6010, -2.9842] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  24000 \n",
      "Loss:  24.7477 \n",
      "Output:  [-5.6683,  7.7033, -3.3903,  3.2299] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  25000 \n",
      "Loss:  57.2718 \n",
      "Output:  [-6.7069, 10.4475,  0.5474, -7.7615] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  26000 \n",
      "Loss:  0.0993 \n",
      "Output:  [ 0.0466, -0.5256, -0.2946,  0.8207] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  27000 \n",
      "Loss:  5.9986 \n",
      "Output:  [-1.0035,  2.2586,  0.6080, -4.2110] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  28000 \n",
      "Loss:  64.2666 \n",
      "Output:  [-11.8922,   6.1603,  -4.0417,   8.5251] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  29000 \n",
      "Loss:  38.3554 \n",
      "Output:  [ 0.0638,  8.2730,  1.7967, -8.9931] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  30000 \n",
      "Loss:  819.9979 \n",
      "Output:  [ 48.5014, -28.4921,   7.0200,   2.9238] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  31000 \n",
      "Loss:  26.8908 \n",
      "Output:  [ 2.9355, -3.3583, -2.0919,  8.6934] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  32000 \n",
      "Loss:  11.3261 \n",
      "Output:  [-1.6865,  4.6734, -1.0488, -4.0523] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  33000 \n",
      "Loss:  14.5061 \n",
      "Output:  [ 1.1372, -0.8269, -0.8512,  7.2574] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  34000 \n",
      "Loss:  2.8228 \n",
      "Output:  [ 1.8445, -2.6365,  0.4709,  1.8462] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  35000 \n",
      "Loss:  6.6452 \n",
      "Output:  [-2.3642,  2.8965,  0.1820, -2.5452] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  36000 \n",
      "Loss:  0.3879 \n",
      "Output:  [-1.0433, -0.1229,  0.6216,  0.7516] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  37000 \n",
      "Loss:  25.0023 \n",
      "Output:  [ 2.9016, -3.4735, -1.4462,  8.3358] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  38000 \n",
      "Loss:  2.8116 \n",
      "Output:  [ 2.2996,  0.2273, -1.1334,  2.0191] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  39000 \n",
      "Loss:  9.8415 \n",
      "Output:  [ 4.0879, -4.5460,  1.3345,  1.4564] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  40000 \n",
      "Loss:  1031.1625 \n",
      "Output:  [ 43.7785, -43.8514,  13.3314,  11.3644] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  41000 \n",
      "Loss:  7.2521 \n",
      "Output:  [-0.3056,  0.8501, -2.1100,  4.9437] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  42000 \n",
      "Loss:  1.2123 \n",
      "Output:  [ 0.7182, -1.4431,  1.4978,  1.0848] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  43000 \n",
      "Loss:  0.9950 \n",
      "Output:  [-0.9763,  1.2468, -0.6379, -0.0322] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  44000 \n",
      "Loss:  96.0197 \n",
      "Output:  [ 12.5262, -13.8072,   4.1804,   5.1400] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  45000 \n",
      "Loss:  12.0951 \n",
      "Output:  [ 3.3600, -5.4091,  1.7247,  2.7032] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  46000 \n",
      "Loss:  3.5018 \n",
      "Output:  [-1.6387,  4.1952, -0.4645, -0.9468] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  47000 \n",
      "Loss:  3.2859 \n",
      "Output:  [ 2.8230, -1.0708, -0.0168,  3.0068] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  48000 \n",
      "Loss:  0.2994 \n",
      "Output:  [ 0.3058, -0.3348, -0.5555,  1.8268] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  49000 \n",
      "Loss:  2.4413 \n",
      "Output:  [ 0.8458, -1.7954,  0.3121,  2.3137] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  50000 \n",
      "Loss:  0.5674 \n",
      "Output:  [ 0.2988, -0.6250, -0.4071,  2.2744] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  51000 \n",
      "Loss:  1328.7637 \n",
      "Output:  [-51.9157,  45.7306,  -4.8861, -24.3949] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  52000 \n",
      "Loss:  10.4810 \n",
      "Output:  [ 5.4326, -3.3794,  0.2793,  1.9549] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  53000 \n",
      "Loss:  3.8994 \n",
      "Output:  [-1.7532,  3.8081, -1.8915,  1.0299] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  54000 \n",
      "Loss:  1.1399 \n",
      "Output:  [ 1.7542, -0.4796, -0.0490,  0.3895] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  55000 \n",
      "Loss:  10.5090 \n",
      "Output:  [ 0.0970,  6.0861, -0.3029, -4.0083] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  56000 \n",
      "Loss:  50.7792 \n",
      "Output:  [-6.0776, 11.0979, -3.0090, -4.5616] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  57000 \n",
      "Loss:  5.3106 \n",
      "Output:  [ 1.4789, -2.8175,  3.2327,  0.1836] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  58000 \n",
      "Loss:  24.0534 \n",
      "Output:  [-5.5758,  7.1901, -1.0347, -3.0472] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  59000 \n",
      "Loss:  1.4073 \n",
      "Output:  [-2.2706,  0.5590,  0.0226,  1.4004] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  60000 \n",
      "Loss:  0.7393 \n",
      "Output:  [ 1.4392, -0.8041, -0.4423,  1.2090] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  61000 \n",
      "Loss:  34.5498 \n",
      "Output:  [ 7.7285, -5.8693, -0.5195,  5.5688] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  62000 \n",
      "Loss:  1.8223 \n",
      "Output:  [ 0.8970, -2.0862,  1.4602,  0.9908] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  63000 \n",
      "Loss:  20.2961 \n",
      "Output:  [ 3.9441, -4.7084, -0.6689,  5.7093] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  64000 \n",
      "Loss:  0.6909 \n",
      "Output:  [-0.4081, -1.3510,  1.8191,  0.3175] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  65000 \n",
      "Loss:  29.4596 \n",
      "Output:  [ 2.8516,  2.8032,  3.0777, -9.8480] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  66000 \n",
      "Loss:  1.3464 \n",
      "Output:  [-0.5130,  0.9421, -0.5654,  1.3358] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  67000 \n",
      "Loss:  0.8137 \n",
      "Output:  [-0.3610, -1.4404,  0.4981,  1.8954] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  68000 \n",
      "Loss:  0.5482 \n",
      "Output:  [ 0.8987, -0.6669, -0.6446,  1.7244] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  69000 \n",
      "Loss:  0.7802 \n",
      "Output:  [ 0.7656,  1.1317, -0.6143,  1.4628] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  70000 \n",
      "Loss:  9.9955 \n",
      "Output:  [ 3.8434, -4.3901,  2.2640,  1.9008] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  71000 \n",
      "Loss:  5.7238 \n",
      "Output:  [ 3.3275, -1.7156, -0.3159,  2.6735] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  72000 \n",
      "Loss:  88.2067 \n",
      "Output:  [ -6.4471,  13.0756,   1.6236, -11.1248] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  73000 \n",
      "Loss:  3.0518 \n",
      "Output:  [ 3.4925, -1.3803,  1.5846, -1.2564] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  74000 \n",
      "Loss:  3.3517 \n",
      "Output:  [ 2.4183, -2.0065,  0.1106,  1.6559] \n",
      "Target:  [0., 0., 1., 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iteration:  75000 \n",
      "Loss:  1.0068 \n",
      "Output:  [-0.0763, -0.7447,  1.5186, -0.0891] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  76000 \n",
      "Loss:  23.5819 \n",
      "Output:  [-4.8161,  8.5801, -2.1735, -2.9919] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  77000 \n",
      "Loss:  0.1578 \n",
      "Output:  [-0.1539, -0.6304,  0.4470,  0.8979] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  78000 \n",
      "Loss:  10.6676 \n",
      "Output:  [ 2.7381, -3.1157, -0.5427,  4.2355] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  79000 \n",
      "Loss:  26.0278 \n",
      "Output:  [ 6.5276, -7.4922,  2.3819,  3.4279] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  80000 \n",
      "Loss:  2.2599 \n",
      "Output:  [ 1.0924, -1.3752, -0.2129,  2.1175] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  81000 \n",
      "Loss:  1.8312 \n",
      "Output:  [-1.6250,  1.4725, -0.5448,  0.3600] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  82000 \n",
      "Loss:  4.6755 \n",
      "Output:  [ 2.7427, -1.8763, -0.0731,  1.7032] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  83000 \n",
      "Loss:  1.5679 \n",
      "Output:  [ 1.5716, -1.5903,  0.5108,  1.0166] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  84000 \n",
      "Loss:  0.1201 \n",
      "Output:  [-0.3369,  0.3607, -0.4461,  1.1945] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  85000 \n",
      "Loss:  0.2086 \n",
      "Output:  [-0.4659,  0.6743, -0.0489,  0.5994] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  86000 \n",
      "Loss:  0.6647 \n",
      "Output:  [-0.0477,  0.8274,  1.8697, -1.1024] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  87000 \n",
      "Loss:  2.0366 \n",
      "Output:  [ 0.4239,  2.1857, -2.0116,  1.5857] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  88000 \n",
      "Loss:  1.0893 \n",
      "Output:  [-0.1503,  0.4430, -0.6644,  1.8928] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  89000 \n",
      "Loss:  30.7937 \n",
      "Output:  [ 6.2051, -6.3754, -0.1643,  5.4998] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  90000 \n",
      "Loss:  1.2106 \n",
      "Output:  [-1.6323,  1.3710, -0.1832,  0.4856] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  91000 \n",
      "Loss:  21.8142 \n",
      "Output:  [-3.8993,  7.0754, -1.0079, -4.2378] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  92000 \n",
      "Loss:  7.5878 \n",
      "Output:  [ 2.7320, -2.7427,  0.1470,  2.9762] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  93000 \n",
      "Loss:  3.0737 \n",
      "Output:  [ 1.8586, -1.2984,  0.0461,  1.8857] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  94000 \n",
      "Loss:  596.2802 \n",
      "Output:  [ 25.2712, -29.7515,  -6.4936,  28.3757] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  95000 \n",
      "Loss:  61.6646 \n",
      "Output:  [-7.2274, 11.9609, -2.6438, -5.3773] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  96000 \n",
      "Loss:  1.1759 \n",
      "Output:  [-1.3517,  1.2591, -0.1350, -0.0547] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  97000 \n",
      "Loss:  39.7402 \n",
      "Output:  [-6.0822,  9.3976, -0.3982, -4.5089] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  98000 \n",
      "Loss:  7.2998 \n",
      "Output:  [-3.9536,  3.3833, -1.3510,  0.4562] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  99000 \n",
      "Loss:  0.0746 \n",
      "Output:  [ 0.3019,  0.2958, -0.3035,  1.1662] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  100000 \n",
      "Loss:  3.1271 \n",
      "Output:  [ 1.8605, -2.2696,  0.4487,  1.8953] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  101000 \n",
      "Loss:  10.8219 \n",
      "Output:  [-2.9771,  5.0702, -1.3261, -0.0680] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  102000 \n",
      "Loss:  24.6865 \n",
      "Output:  [-4.0410,  6.3636,  1.5627, -5.5133] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  103000 \n",
      "Loss:  1.3811 \n",
      "Output:  [ 0.4295, -1.9069,  1.3035,  1.0657] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  104000 \n",
      "Loss:  13.8152 \n",
      "Output:  [ 1.4340, -5.8031,  1.5196,  5.1496] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  105000 \n",
      "Loss:  30.6939 \n",
      "Output:  [ 7.0979, -7.3556,  1.1028,  5.1321] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  106000 \n",
      "Loss:  4.6140 \n",
      "Output:  [ 1.7670, -1.9504,  0.0202,  2.5746] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  107000 \n",
      "Loss:  2.2879 \n",
      "Output:  [-2.2533,  2.8292, -0.7698,  0.3685] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  108000 \n",
      "Loss:  0.4065 \n",
      "Output:  [ 0.1308,  0.8599, -0.8787,  1.3120] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  109000 \n",
      "Loss:  6.4586 \n",
      "Output:  [ 3.7753, -2.4054, -0.1123,  2.1350] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  110000 \n",
      "Loss:  4.0887 \n",
      "Output:  [ 2.3147, -1.8960,  0.5647,  1.5138] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  111000 \n",
      "Loss:  0.7401 \n",
      "Output:  [ 0.4500, -1.2375,  0.9109,  1.1039] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  112000 \n",
      "Loss:  6.9590 \n",
      "Output:  [-2.1065,  5.2746, -1.5510, -1.6496] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  113000 \n",
      "Loss:  0.2903 \n",
      "Output:  [-0.1374,  0.4453,  0.1356,  0.0380] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  114000 \n",
      "Loss:  3.6766 \n",
      "Output:  [ 0.7888,  3.6960, -0.7337, -0.6802] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  115000 \n",
      "Loss:  2.4152 \n",
      "Output:  [ 1.8669, -2.0755,  2.2496,  0.5535] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  116000 \n",
      "Loss:  6.3521 \n",
      "Output:  [ 0.2917, -1.8934, -1.6604,  5.3568] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  117000 \n",
      "Loss:  14.2227 \n",
      "Output:  [ 3.5663, -4.7287,  0.7972,  3.2741] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  118000 \n",
      "Loss:  3.0591 \n",
      "Output:  [-2.0754,  3.5094, -1.2499, -0.2644] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  119000 \n",
      "Loss:  14.2053 \n",
      "Output:  [ 3.9909, -5.6149,  2.9322,  1.8767] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  120000 \n",
      "Loss:  3.4721 \n",
      "Output:  [ 1.6736, -2.4282,  0.7447,  2.2642] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  121000 \n",
      "Loss:  10.7350 \n",
      "Output:  [-3.4352,  4.2800,  0.2037, -2.2157] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  122000 \n",
      "Loss:  0.2736 \n",
      "Output:  [-0.1464,  2.0266, -0.0133,  0.1366] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  123000 \n",
      "Loss:  1.0653 \n",
      "Output:  [ 0.0780, -1.5086,  0.2275,  2.3884] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  124000 \n",
      "Loss:  3.9440 \n",
      "Output:  [-2.3430,  3.7539, -1.6428, -0.0591] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  125000 \n",
      "Loss:  6.1788 \n",
      "Output:  [-1.5175,  3.0299, -2.3388,  1.4436] \n",
      "Target:  [0., 0., 1., 0.]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-6cb5a76513c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mlossDuplicationCounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprevloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Does the update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "while (good < 10):\n",
    "    if float(prevloss)<1:\n",
    "        good+=1\n",
    "    else:\n",
    "        good = 0\n",
    "        \n",
    "    a=r(0, (len(contents)/15-1))\n",
    "    chars = torch.tensor(contents[(a*15):(a*15+14)])\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    out = net(chars)\n",
    "    \n",
    "    start=a*15\n",
    "    #print(contents[start+14])\n",
    "    if (contents[start+14]=='Marcin'):\n",
    "        target = torch.tensor([1., 0., 0., 0.])\n",
    "    elif (contents[start+14]=='Bartek'):\n",
    "        target = torch.tensor([0., 1., 0., 0.])\n",
    "    elif (contents[start+14]=='Maciek'):\n",
    "        target = torch.tensor([0., 0., 1., 0.,])\n",
    "    elif (contents[start+14]=='Artur'):\n",
    "        target = torch.tensor([0., 0., 0., 1.,])\n",
    "    loss = criterion(out, target)\n",
    "    #print('loss', float(loss))\n",
    "    if prevloss == loss:\n",
    "        lossDuplicationCounter +=1\n",
    "        print('loss duplicate #', lossDuplicationCounter)\n",
    "    else:\n",
    "        lossDuplicationCounter = 0\n",
    "    prevloss = loss\n",
    "    loss.backward(retain_graph=True)\n",
    "    #loss.backward()\n",
    "    optimizer.step()   # Does the update\n",
    "    if i%1000==0:\n",
    "        print(\"\\n\\niteration: \", i, \n",
    "              \"\\nLoss: \", ((str(loss)).strip('tensor()')).strip(', grad_fn=<MseLossBackward>) '), \n",
    "              '\\nOutput: ', ((str(out)).strip('tensor(')).strip(', grad_fn=<AddBackward0>)'),\n",
    "              '\\nTarget: ', str(target).strip('tensor(').strip(')'))\n",
    "    i+=1\n",
    "print(\"Learning time: \\n\\t\", time.time()-start)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prevloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\niteration: \", i, \n",
    "              \"\\nLoss: \", ((str(loss)).strip('tensor()')).strip(', grad_fn=<MseLossBackward>) '), \n",
    "              '\\nOutput: ', ((str(out)).strip('tensor(')).strip(', grad_fn=<AddBackward0>)').strip(', grad_fn=<Softmax'),\n",
    "              '\\nTarget: ', str(target).strip('tensor(').strip(')'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print\n",
    "i=0\n",
    "for filename in glob.glob(path):\n",
    "    #a=r(0, (len(contents)/15-1))\n",
    "    chars = torch.tensor(contents[(i*15):(i*15+14)])\n",
    "    #print(str(net(chars)).strip(\", grad_fn=<AddBackward0>)\").strip(\"tensor(\"), \"\\t : \",contents[i*15+14])\n",
    "    print(((str(net(chars))).strip('tensor(')).strip(', grad_fn=<AddBackward0>)').strip(', grad_fn=<Softmax'), \" : \", contents[i*15+14])\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in net.state_dict():\n",
    "    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, \"net.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "haba = torch.load(\"net.pt\")\n",
    "haba.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "i=0\n",
    "ilezg=0\n",
    "for filename in glob.glob(path):\n",
    "    tt=torch.tensor(contents[(a*15):(a*15+14)])\n",
    "    who = contents[i*15+14]\n",
    "    predykcja = haba(tt)\n",
    "    print(str(predykcja).strip('tensor(').strip(', grad_fn=<AddBackward0>)').strip(', grad_fn=<SoftmaxBackward>)')) \n",
    "    predlist = predykcja.tolist().index(max(predykcja.tolist()))\n",
    "    predykcjaOsoba=''\n",
    "    if predlist == 0:\n",
    "        predykcjaOsoba='Marcin'\n",
    "    elif predlist == 1:\n",
    "        predykcjaOsoba='Bartek'\n",
    "    elif predlist == 2:\n",
    "        predykcjaOsoba='Maciek'\n",
    "    elif predlist == 3:\n",
    "        predykcjaOsoba='Artur'\n",
    "    else:\n",
    "        print('ERROR!!!')\n",
    "    print(i, who, ' : \\n', str(tt).strip('tensor(').strip(')').strip(', grad_fn=<Softmax')), #'\\n', str(predykcja).strip('tensor(').strip(', grad_fn=<AddBackward0>)').strip(', grad_fn=<SoftmaxBackward>)'))\n",
    "    i+=1\n",
    "    if who == predykcjaOsoba:\n",
    "        ilezg+=1\n",
    "print(ilezg/i*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
