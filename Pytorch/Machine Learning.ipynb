{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "795\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "path = \"./../dist/char*.txt\"\n",
    "contents=[]\n",
    "for filename in glob.glob(path):\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            contents.append(line.strip('\\n'))\n",
    "print(len(contents))\n",
    "i=0\n",
    "while (i<len(contents)-1):\n",
    "    contents[i]=float(contents[i])\n",
    "    i+=1\n",
    "    if ((i+1)%15==0):\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint as r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  :  tensor([1.7000e+02, 1.9600e+02, 2.3915e+02, 2.7594e+02, 4.2629e+00, 4.6510e+00,\n",
      "        1.8965e+01, 1.6539e+01, 9.7704e+04, 7.7159e+03, 9.8711e+00, 7.7954e-01,\n",
      "        5.7453e-02, 4.9622e-02])\n",
      "1  :  tensor([1.3700e+02, 2.0300e+02, 1.9245e+02, 2.8584e+02, 4.7254e+00, 4.8075e+00,\n",
      "        1.6646e+01, 1.8780e+01, 9.7918e+04, 5.9891e+03, 9.8917e+00, 6.0503e-01,\n",
      "        6.9876e-02, 4.8330e-02])\n",
      "2  :  tensor([1.2100e+02, 1.8000e+02, 1.6981e+02, 2.5330e+02, 4.9331e+00, 4.3437e+00,\n",
      "        1.5881e+01, 1.8789e+01, 9.7496e+04, 7.2560e+03, 9.8272e+00, 7.3138e-01,\n",
      "        7.9711e-02, 5.4328e-02])\n",
      "3  :  tensor([1.6400e+02, 1.7700e+02, 2.3065e+02, 2.4905e+02, 4.4259e+00, 4.2629e+00,\n",
      "        1.8905e+01, 1.8064e+01, 9.8584e+04, 9.4879e+03, 9.8960e+00, 9.5251e-01,\n",
      "        5.9634e-02, 5.5542e-02])\n",
      "4  :  tensor([2.0500e+02, 2.1200e+02, 1.3217e+02, 1.3670e+02, 4.9991e+00, 4.9991e+00,\n",
      "        1.7822e+01, 1.7248e+01, 9.8096e+04, 7.5926e+03, 9.8987e+00, 7.6623e-01,\n",
      "        4.7512e-02, 4.5995e-02])\n",
      "5  :  tensor([2.0800e+02, 2.1700e+02, 1.3411e+02, 1.3994e+02, 5.2510e+00, 5.3857e+00,\n",
      "        1.7077e+01, 1.6586e+01, 9.8127e+04, 5.0104e+03, 9.8719e+00, 5.0406e-01,\n",
      "        4.6135e-02, 4.5194e-02])\n",
      "6  :  tensor([2.0400e+02, 2.1600e+02, 1.3152e+02, 1.3929e+02, 4.9991e+00, 5.4781e+00,\n",
      "        1.5611e+01, 1.7447e+01, 9.8457e+04, 4.5087e+03, 9.9241e+00, 4.5447e-01,\n",
      "        4.7951e-02, 4.5417e-02])\n",
      "7  :  tensor([2.2700e+02, 2.3700e+02, 1.4642e+02, 1.5290e+02, 5.2765e+00, 4.9991e+00,\n",
      "        1.6634e+01, 1.6126e+01, 9.8448e+04, 4.2835e+03, 9.9082e+00, 4.3106e-01,\n",
      "        4.3383e-02, 4.1325e-02])\n",
      "8  :  tensor([2.2600e+02, 2.0600e+02, 1.4577e+02, 1.3282e+02, 5.4436e+00, 5.4841e+00,\n",
      "        1.7649e+01, 1.6586e+01, 9.8765e+04, 7.1877e+03, 9.9441e+00, 7.2369e-01,\n",
      "        4.3717e-02, 4.7825e-02])\n",
      "9  :  tensor([2.1600e+02, 2.1600e+02, 1.3929e+02, 1.3929e+02, 5.2510e+00, 5.5659e+00,\n",
      "        1.5803e+01, 1.7705e+01, 9.7870e+04, 5.5116e+03, 9.8809e+00, 5.5645e-01,\n",
      "        4.5593e-02, 4.5602e-02])\n",
      "10  :  tensor([2.0100e+02, 2.3100e+02, 1.2957e+02, 1.4901e+02, 5.1840e+00, 5.2510e+00,\n",
      "        1.6634e+01, 1.7077e+01, 9.7340e+04, 5.9237e+03, 9.8076e+00, 5.9685e-01,\n",
      "        4.8776e-02, 4.2610e-02])\n",
      "11  :  tensor([2.1400e+02, 2.1600e+02, 1.3800e+02, 1.3929e+02, 5.3406e+00, 5.1840e+00,\n",
      "        1.6069e+01, 1.7248e+01, 9.8379e+04, 6.2308e+03, 9.9162e+00, 6.2804e-01,\n",
      "        4.6009e-02, 4.5347e-02])\n",
      "12  :  tensor([2.8200e+02, 2.4500e+02, 1.8205e+02, 1.5808e+02, 5.1840e+00, 5.2288e+00,\n",
      "        1.6634e+01, 1.5632e+01, 9.8374e+04, 5.8761e+03, 9.8938e+00, 5.9098e-01,\n",
      "        3.4929e-02, 4.0024e-02])\n",
      "13  :  tensor([2.1000e+02, 1.8300e+02, 1.3640e+02, 1.1878e+02, 7.7158e+00, 7.7407e+00,\n",
      "        1.3331e+01, 1.3311e+01, 3.9535e+04, 1.8109e+03, 9.9061e+00, 4.5386e-01,\n",
      "        1.8795e-02, 2.1579e-02])\n",
      "14  :  tensor([1.5400e+02, 2.2000e+02, 9.9851e+01, 1.4293e+02, 7.7443e+00, 7.7393e+00,\n",
      "        1.3120e+01, 1.3070e+01, 3.9687e+04, 1.3209e+03, 9.8748e+00, 3.2865e-01,\n",
      "        2.5143e-02, 1.7823e-02])\n",
      "15  :  tensor([1.7500e+02, 3.0100e+02, 1.1356e+02, 1.9579e+02, 7.7320e+00, 7.7502e+00,\n",
      "        1.3331e+01, 1.3087e+01, 3.9683e+04, 1.2161e+03, 9.8936e+00, 3.0319e-01,\n",
      "        2.2560e-02, 1.3252e-02])\n",
      "16  :  tensor([1.9300e+02, 2.5300e+02, 1.2530e+02, 1.6446e+02, 7.7683e+00, 7.8009e+00,\n",
      "        1.3040e+01, 1.2551e+01, 3.9517e+04, 3.6856e+03, 9.8989e+00, 9.2325e-01,\n",
      "        2.0368e-02, 1.5609e-02])\n",
      "17  :  tensor([2.0800e+02, 3.1400e+02, 1.3509e+02, 2.0427e+02, 7.7443e+00, 7.7158e+00,\n",
      "        1.3010e+01, 1.3041e+01, 3.9581e+04, 1.2183e+03, 9.8977e+00, 3.0305e-01,\n",
      "        1.8990e-02, 1.2576e-02])\n",
      "18  :  tensor([1.3000e+02, 2.3700e+02, 8.4188e+01, 1.5402e+02, 7.9499e+00, 7.7158e+00,\n",
      "        1.2962e+01, 1.2794e+01, 3.9233e+04, 1.3025e+03, 9.8377e+00, 3.2661e-01,\n",
      "        2.9869e-02, 1.6650e-02])\n",
      "19  :  tensor([1.3700e+02, 2.7700e+02, 8.8756e+01, 1.8013e+02, 7.7955e+00, 7.7204e+00,\n",
      "        1.3120e+01, 1.3072e+01, 3.9766e+04, 1.2035e+03, 9.8455e+00, 2.9796e-01,\n",
      "        2.7912e-02, 1.4256e-02])\n",
      "20  :  tensor([1.5500e+02, 2.3900e+02, 1.0050e+02, 1.5533e+02, 7.7393e+00, 7.7427e+00,\n",
      "        1.3087e+01, 1.3331e+01, 3.9319e+04, 1.2841e+03, 9.8916e+00, 3.2304e-01,\n",
      "        2.5729e-02, 1.6205e-02])\n",
      "21  :  tensor([1.2300e+02, 2.2000e+02, 7.9620e+01, 1.4293e+02, 7.7419e+00, 7.7280e+00,\n",
      "        1.2730e+01, 1.3107e+01, 3.9746e+04, 1.3701e+03, 9.9217e+00, 3.4201e-01,\n",
      "        3.1756e-02, 1.8014e-02])\n",
      "22  :  tensor([1.3200e+02, 2.2300e+02, 8.5493e+01, 1.4488e+02, 7.7427e+00, 7.7158e+00,\n",
      "        1.2867e+01, 1.3084e+01, 3.9436e+04, 1.3974e+03, 9.8615e+00, 3.4945e-01,\n",
      "        2.9318e-02, 1.7516e-02])\n",
      "23  :  tensor([1.7100e+02, 2.5900e+02, 1.1095e+02, 1.6838e+02, 7.8335e+00, 7.8095e+00,\n",
      "        1.3266e+01, 1.3116e+01, 3.9639e+04, 1.3465e+03, 9.9097e+00, 3.3663e-01,\n",
      "        2.3129e-02, 1.5351e-02])\n",
      "24  :  tensor([1.3900e+02, 2.4600e+02, 9.0062e+01, 1.5989e+02, 7.7683e+00, 7.7551e+00,\n",
      "        1.2555e+01, 1.3120e+01, 3.9856e+04, 1.2786e+03, 9.9366e+00, 3.1878e-01,\n",
      "        2.7281e-02, 1.6049e-02])\n",
      "25  :  tensor([1.6800e+02, 2.4300e+02, 1.0899e+02, 1.5794e+02, 7.7443e+00, 7.7419e+00,\n",
      "        1.3306e+01, 1.3107e+01, 3.9452e+04, 1.4540e+03, 9.9075e+00, 3.6515e-01,\n",
      "        2.3458e-02, 1.6309e-02])\n",
      "26  :  tensor([1.4900e+02, 2.5700e+02, 9.6588e+01, 1.6707e+02, 7.7427e+00, 7.7551e+00,\n",
      "        1.3306e+01, 1.2816e+01, 3.9448e+04, 1.3907e+03, 9.8398e+00, 3.4689e-01,\n",
      "        2.5980e-02, 1.5315e-02])\n",
      "27  :  tensor([1.4900e+02, 2.5600e+02, 9.6588e+01, 1.6642e+02, 7.7646e+00, 7.8969e+00,\n",
      "        1.2962e+01, 1.3306e+01, 3.9522e+04, 1.4244e+03, 9.9302e+00, 3.5788e-01,\n",
      "        2.6544e-02, 1.5109e-02])\n",
      "28  :  tensor([1.7800e+02, 2.7600e+02, 1.1551e+02, 1.7947e+02, 8.0189e+00, 7.7427e+00,\n",
      "        1.3115e+01, 1.3041e+01, 3.9658e+04, 1.0462e+03, 9.8996e+00, 2.6109e-01,\n",
      "        2.1904e-02, 1.4366e-02])\n",
      "29  :  tensor([1.3400e+02, 2.8200e+02, 8.6799e+01, 1.8339e+02, 7.7796e+00, 7.7427e+00,\n",
      "        1.3009e+01, 1.3162e+01, 3.9298e+04, 1.0546e+03, 9.8590e+00, 2.6456e-01,\n",
      "        2.9254e-02, 1.4092e-02])\n",
      "30  :  tensor([1.7800e+02, 3.1900e+02, 1.1551e+02, 2.0754e+02, 7.7443e+00, 7.7158e+00,\n",
      "        1.3084e+01, 1.3009e+01, 3.9488e+04, 9.2509e+02, 9.8993e+00, 2.3191e-01,\n",
      "        2.2017e-02, 1.2288e-02])\n",
      "31  :  tensor([2.2600e+02, 2.9400e+02, 1.4684e+02, 1.9122e+02, 7.7158e+00, 7.7705e+00,\n",
      "        1.3162e+01, 1.3266e+01, 3.9556e+04, 1.0364e+03, 9.7960e+00, 2.5667e-01,\n",
      "        1.7350e-02, 1.3486e-02])\n",
      "32  :  tensor([1.7700e+02, 2.2800e+02, 1.1486e+02, 1.4815e+02, 7.7480e+00, 7.7320e+00,\n",
      "        1.3237e+01, 1.3009e+01, 3.9501e+04, 1.1424e+03, 9.8729e+00, 2.8560e-01,\n",
      "        2.2390e-02, 1.7390e-02])\n",
      "33  :  tensor([1.8700e+02, 2.7400e+02, 1.2139e+02, 1.7817e+02, 7.7705e+00, 7.7443e+00,\n",
      "        1.2957e+01, 1.3084e+01, 3.9234e+04, 1.1389e+03, 9.8826e+00, 2.8687e-01,\n",
      "        2.1037e-02, 1.4460e-02])\n",
      "34  :  tensor([1.4800e+02, 2.6800e+02, 9.5935e+01, 1.7425e+02, 7.7443e+00, 7.7280e+00,\n",
      "        1.2794e+01, 1.3306e+01, 3.9467e+04, 1.1817e+03, 9.8668e+00, 2.9542e-01,\n",
      "        2.6946e-02, 1.4731e-02])\n",
      "35  :  tensor([1.4300e+02, 1.8000e+02, 5.7745e+01, 7.2791e+01, 5.2732e+00, 5.4549e+00,\n",
      "        1.5429e+01, 1.5197e+01, 7.9757e+04, 4.8122e+03, 9.9759e+00, 6.0190e-01,\n",
      "        5.5343e-02, 4.3933e-02])\n",
      "36  :  tensor([1.3600e+02, 2.0300e+02, 5.4899e+01, 8.2144e+01, 5.6409e+00, 5.5057e+00,\n",
      "        1.5429e+01, 1.5329e+01, 7.9357e+04, 4.9368e+03, 9.9159e+00, 6.1687e-01,\n",
      "        5.8199e-02, 3.8616e-02])\n",
      "37  :  tensor([1.5300e+02, 1.7500e+02, 6.1812e+01, 7.0758e+01, 5.7200e+00, 5.3068e+00,\n",
      "        1.5320e+01, 1.5251e+01, 7.8484e+04, 4.5058e+03, 9.7580e+00, 5.6022e-01,\n",
      "        5.2046e-02, 4.5234e-02])\n",
      "38  :  tensor([1.4000e+02, 1.9100e+02, 5.6525e+01, 7.7265e+01, 6.0021e+00, 5.4710e+00,\n",
      "        1.5106e+01, 1.4970e+01, 7.9453e+04, 3.9024e+03, 9.8786e+00, 4.8520e-01,\n",
      "        5.6129e-02, 4.1691e-02])\n",
      "39  :  tensor([1.0800e+02, 1.7500e+02, 4.3512e+01, 7.0758e+01, 5.7349e+00, 5.3194e+00,\n",
      "        1.5251e+01, 1.5329e+01, 7.8568e+04, 3.6989e+03, 9.7868e+00, 4.6074e-01,\n",
      "        7.1426e-02, 4.5229e-02])\n",
      "40  :  tensor([1.1700e+02, 1.5200e+02, 4.7172e+01, 6.1405e+01, 5.6005e+00, 5.3068e+00,\n",
      "        1.5303e+01, 1.5320e+01, 7.9762e+04, 5.9233e+03, 9.9579e+00, 7.3949e-01,\n",
      "        6.5932e-02, 5.2072e-02])\n",
      "41  :  tensor([1.3300e+02, 1.8700e+02, 5.3679e+01, 7.5638e+01, 5.5203e+00, 5.2732e+00,\n",
      "        1.5175e+01, 1.5251e+01, 7.9165e+04, 3.2447e+03, 9.8746e+00, 4.0473e-01,\n",
      "        5.9504e-02, 4.2326e-02])\n",
      "42  :  tensor([1.3200e+02, 1.8700e+02, 5.3272e+01, 7.5638e+01, 5.6005e+00, 5.5047e+00,\n",
      "        1.5228e+01, 1.4685e+01, 7.8644e+04, 2.6093e+03, 9.7852e+00, 3.2465e-01,\n",
      "        5.9955e-02, 4.2588e-02])\n",
      "43  :  tensor([1.3000e+02, 1.8300e+02, 5.2459e+01, 7.4011e+01, 5.4549e+00, 5.5292e+00,\n",
      "        1.5322e+01, 1.5318e+01, 7.9846e+04, 2.5762e+03, 9.9533e+00, 3.2114e-01,\n",
      "        6.0877e-02, 4.3257e-02])\n",
      "44  :  tensor([1.4600e+02, 2.0500e+02, 5.8965e+01, 8.2958e+01, 5.6553e+00, 5.4192e+00,\n",
      "        1.5258e+01, 1.5322e+01, 7.8997e+04, 3.0596e+03, 9.8121e+00, 3.8002e-01,\n",
      "        5.4548e-02, 3.8610e-02])\n",
      "45  :  tensor([1.1900e+02, 1.9300e+02, 4.7985e+01, 7.8078e+01, 5.6005e+00, 5.3978e+00,\n",
      "        1.5426e+01, 1.5322e+01, 7.8849e+04, 3.7705e+03, 9.8328e+00, 4.7019e-01,\n",
      "        6.4042e-02, 4.1005e-02])\n",
      "46  :  tensor([1.3300e+02, 1.7600e+02, 5.3679e+01, 7.1165e+01, 5.6244e+00, 5.3194e+00,\n",
      "        1.5228e+01, 1.5258e+01, 7.9815e+04, 4.2108e+03, 9.8965e+00, 5.2210e-01,\n",
      "        5.9887e-02, 4.4966e-02])\n",
      "47  :  tensor([1.3700e+02, 1.5900e+02, 5.5305e+01, 6.4252e+01, 5.4490e+00, 5.5309e+00,\n",
      "        1.5251e+01, 1.5045e+01, 8.0175e+04, 6.6013e+03, 9.9944e+00, 8.2289e-01,\n",
      "        5.7774e-02, 4.9774e-02])\n",
      "48  :  tensor([1.3300e+02, 1.8900e+02, 5.3679e+01, 7.6451e+01, 5.6005e+00, 5.4049e+00,\n",
      "        1.5131e+01, 1.5318e+01, 7.8935e+04, 3.9692e+03, 9.8966e+00, 4.9764e-01,\n",
      "        5.7917e-02, 4.1884e-02])\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for a in range(0, 49):\n",
    "    i=r(0, (len(contents)/15-1))\n",
    "    tt=torch.tensor(contents[(a*15):(a*15+14)])\n",
    "    print(a, ' : ', tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=14, out_features=14, bias=True)\n",
    "        self.fc2 = nn.Linear(in_features=14, out_features=14, bias=True)\n",
    "        self.out = nn.Linear(in_features=14, out_features = 4, bias=True)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        #1st layer\n",
    "        t = self.fc1(t)\n",
    "        #2nd layer\n",
    "        t = self.fc2(t)\n",
    "        #output layer\n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Network()\n",
    "params=list(net.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "net.zero_grad()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0000000005)\n",
    "lossDuplicationCounter = 0\n",
    "prevloss=0\n",
    "loss = 4\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iteration:  0 \n",
      "loss:  tensor(18304984., grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ -621.2948, -3564.9189,  2721.1582, -7259.8940],\n",
      "       grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  1000 \n",
      "loss:  tensor(802.6117, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-11.2109,   6.9219,  54.7534,  -5.2382], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  2000 \n",
      "loss:  tensor(1591.9047, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-23.9584,   5.3503,  73.9562, -16.1891], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  3000 \n",
      "loss:  tensor(4193.7837, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-57.5021,  -5.2001, 107.1790, -43.2071], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  4000 \n",
      "loss:  tensor(651.2397, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-16.9041,   2.0704,  47.0386, -10.2681], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  5000 \n",
      "loss:  tensor(829.8742, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-18.9517,  -2.9757,  53.1846, -10.0849], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  6000 \n",
      "loss:  tensor(115.4474, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([  2.2419,  -2.6255, -21.1314,  -0.8254], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  7000 \n",
      "loss:  tensor(413.9807, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-25.4015, -14.0645,  21.1614, -18.1069], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  8000 \n",
      "loss:  tensor(95.5114, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([  4.3933,  -5.3327, -18.2634,   0.1308], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  9000 \n",
      "loss:  tensor(255.0331, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-3.6092,  1.9980, 31.6706,  1.3002], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  10000 \n",
      "loss:  tensor(311.7908, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 17.6407,   3.5583, -29.4348,   8.5432], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  11000 \n",
      "loss:  tensor(162.6771, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-13.6713,  -9.3864,  -7.5227, -16.8636], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  12000 \n",
      "loss:  tensor(71.9465, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 0.8840,  8.2675, 14.7865,  0.8800], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  13000 \n",
      "loss:  tensor(105.2036, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-2.7682, -0.5990, 20.2824,  2.1898], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  14000 \n",
      "loss:  tensor(795.7358, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-38.6853, -22.6620,  12.2451, -30.9825], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  15000 \n",
      "loss:  tensor(320.6107, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-21.9877, -10.0908,  24.3538,  -9.2007], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  16000 \n",
      "loss:  tensor(88.4181, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 4.3717,  4.0472, 16.9993,  6.4041], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  17000 \n",
      "loss:  tensor(383.6185, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([24.1782, 15.0001,  2.2952, 27.8257], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  18000 \n",
      "loss:  tensor(8.9705, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-2.7621, -4.3291,  2.7698, -0.3565], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  19000 \n",
      "loss:  tensor(239.3116, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 11.7460,  -0.7589, -28.5179,  -1.3305], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  20000 \n",
      "loss:  tensor(6.2977, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([1.8159, 1.8730, 2.9883, 4.0750], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  21000 \n",
      "loss:  tensor(69.4928, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 4.6517, 11.3175, 11.1825,  2.7886], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  22000 \n",
      "loss:  tensor(129.3064, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-11.5054, -13.0153, -11.1529,  -8.5428], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  23000 \n",
      "loss:  tensor(15.3719, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-5.0474,  1.3805,  3.4822, -3.6883], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  24000 \n",
      "loss:  tensor(620.4519, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([31.2578, 26.3558,  4.0711, 29.1702], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  25000 \n",
      "loss:  tensor(95.9879, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 3.8795,  7.2569, 17.1456,  5.7189], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  26000 \n",
      "loss:  tensor(17.4891, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([2.7502, 0.2135, 7.1586, 4.3320], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  27000 \n",
      "loss:  tensor(48.7212, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 4.0768,  4.6081, 11.7901,  5.2455], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  28000 \n",
      "loss:  tensor(4.8615, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 0.4548, -2.2229, -2.8564, -1.4777], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  29000 \n",
      "loss:  tensor(84.1750, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 4.7204,  6.3383, 15.2500,  7.4561], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  30000 \n",
      "loss:  tensor(41.7248, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([5.8741, 7.3789, 6.4942, 6.9809], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  31000 \n",
      "loss:  tensor(104.5126, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 6.4097,  3.2727,  9.8281, 16.7775], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  32000 \n",
      "loss:  tensor(53.0942, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 4.6727,  5.0396, 11.5711,  6.5905], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  33000 \n",
      "loss:  tensor(16.4054, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([4.0834, 1.6747, 5.1875, 5.3855], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  34000 \n",
      "loss:  tensor(39.7202, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-4.3339,  0.4364, 11.7656,  2.2155], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  35000 \n",
      "loss:  tensor(51.8798, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 5.3299,  2.9571, 10.7341,  8.4261], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  36000 \n",
      "loss:  tensor(197.1960, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([15.4743, 15.0251, 10.3223, 15.7317], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  37000 \n",
      "loss:  tensor(31.9784, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.5313, -0.5338, -8.8506, -5.8521], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  38000 \n",
      "loss:  tensor(26.1144, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-6.3867, -6.7909,  3.9822, -0.3009], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  39000 \n",
      "loss:  tensor(53.4659, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 5.7785,  6.1732, 10.3318,  6.9680], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  40000 \n",
      "loss:  tensor(13.7058, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 0.6343, -2.6424, -6.0718, -2.2515], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  41000 \n",
      "loss:  tensor(66.6474, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 6.8697,  6.6789, 11.3208,  7.8285], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  42000 \n",
      "loss:  tensor(99.2816, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([10.1296,  8.2264, 11.7987, 10.3613], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  43000 \n",
      "loss:  tensor(32.2933, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.5881, 3.6745, 6.1905, 6.8263], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  44000 \n",
      "loss:  tensor(18.0850, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([2.7353, 3.7654, 6.7338, 3.3099], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  45000 \n",
      "loss:  tensor(99.4407, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 7.3399, 11.2462, 13.5499,  7.4368], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  46000 \n",
      "loss:  tensor(31.9476, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([5.9298, 2.4923, 6.9102, 7.2182], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  47000 \n",
      "loss:  tensor(3.8325, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([1.0802, 3.2244, 1.9306, 1.1993], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  48000 \n",
      "loss:  tensor(6.1382, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.1856, -3.0109, -1.4717, -2.4520], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  49000 \n",
      "loss:  tensor(65.7772, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([8.3706, 5.8848, 9.6726, 9.0531], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  50000 \n",
      "loss:  tensor(19.4045, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 1.6173,  4.2809, -7.5141,  0.5371], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  51000 \n",
      "loss:  tensor(16.3067, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-6.0006, -1.0531, -0.8047, -4.2405], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  52000 \n",
      "loss:  tensor(11.7068, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-4.6669, -4.8516,  1.1441,  0.5523], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  53000 \n",
      "loss:  tensor(46.8424, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 2.1645, 10.4128,  8.6077,  1.4080], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iteration:  54000 \n",
      "loss:  tensor(60.3276, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([8.4327, 5.4482, 8.9799, 8.7382], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  55000 \n",
      "loss:  tensor(64.0411, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 6.0033, 10.0326,  9.8986,  6.3682], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  56000 \n",
      "loss:  tensor(15.0747, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.1465,  7.0599,  3.2136,  0.6708], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  57000 \n",
      "loss:  tensor(22.4483, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.2849,  7.6876,  1.2255, -4.2479], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  58000 \n",
      "loss:  tensor(116.4520, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 7.4523,  1.7234, 13.6175, 15.8952], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  59000 \n",
      "loss:  tensor(38.3247, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([7.3332, 4.2174, 6.7521, 7.0121], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  60000 \n",
      "loss:  tensor(69.6572, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([8.1752, 6.7747, 9.9424, 9.1882], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  61000 \n",
      "loss:  tensor(100.0915, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 9.5848,  7.7446, 12.0165, 11.2040], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  62000 \n",
      "loss:  tensor(60.0918, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([9.5795, 4.9078, 7.6033, 9.1673], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  63000 \n",
      "loss:  tensor(18.1256, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([3.9265, 4.4388, 5.2730, 4.0948], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  64000 \n",
      "loss:  tensor(19.6160, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([4.7994, 4.7519, 4.4088, 4.6622], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  65000 \n",
      "loss:  tensor(25.7003, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.3895, -4.5220, -7.0349, -4.5617], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  66000 \n",
      "loss:  tensor(101.6065, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([10.1508, 10.3192, 11.1790,  9.4813], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  67000 \n",
      "loss:  tensor(8.8227, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.6940, -0.4135, -5.1430, -1.4082], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  68000 \n",
      "loss:  tensor(77.0732, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 8.5854,  6.6800, 10.4640,  9.9703], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  69000 \n",
      "loss:  tensor(28.1149, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([8.2769, 7.2218, 0.8042, 2.1436], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  70000 \n",
      "loss:  tensor(321.5481, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 8.9498,  6.4159, 25.2378, 23.3427], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  71000 \n",
      "loss:  tensor(57.1278, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 5.6124,  8.4755, 10.0292,  5.9591], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  72000 \n",
      "loss:  tensor(129.6158, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ -6.3421,  -4.0576, -16.8633, -12.3195], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  73000 \n",
      "loss:  tensor(86.5325, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([10.1796,  8.8013,  9.9540,  9.1216], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  74000 \n",
      "loss:  tensor(25.5866, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([5.7767, 2.2598, 5.4771, 6.8199], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  75000 \n",
      "loss:  tensor(180.1411, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ -7.8219,  -5.3431, -20.5671, -13.4162], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  76000 \n",
      "loss:  tensor(24.9515, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([3.9512, 5.9785, 6.1424, 4.2747], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  77000 \n",
      "loss:  tensor(49.3921, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([8.6412, 6.2977, 5.9760, 7.8938], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  78000 \n",
      "loss:  tensor(42.3671, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([7.0704, 5.6463, 7.0860, 7.1144], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  79000 \n",
      "loss:  tensor(9.5599, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([3.3606, 2.3508, 3.2112, 4.3329], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  80000 \n",
      "loss:  tensor(23.2806, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-2.7493, -7.1613, -5.4349, -1.1775], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  81000 \n",
      "loss:  tensor(57.8235, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([8.1573, 5.9341, 8.6857, 8.3551], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  82000 \n",
      "loss:  tensor(5.3442, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-3.3257, -0.3546, -1.7690, -1.6574], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  83000 \n",
      "loss:  tensor(16.2858, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([0.9149, 3.9979, 6.6909, 2.8853], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  84000 \n",
      "loss:  tensor(3.3565, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 2.2025, -1.9360, -1.2132, -0.8316], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  85000 \n",
      "loss:  tensor(5.4907, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 3.8608,  2.1442, -0.9881,  2.2179], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  86000 \n",
      "loss:  tensor(12.6603, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.1602,  0.4667, -5.6198, -3.1827], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  87000 \n",
      "loss:  tensor(30.1452, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-2.7030e-03, -4.4752e+00, -8.3078e+00, -4.6154e+00],\n",
      "       grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  88000 \n",
      "loss:  tensor(28.1829, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.8272, 4.5383, 4.4030, 6.1125], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  89000 \n",
      "loss:  tensor(33.7375, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([7.8587, 3.2273, 4.3458, 7.6249], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  90000 \n",
      "loss:  tensor(15.1176, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-2.1616,  0.9899, -3.3325, -5.6115], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  91000 \n",
      "loss:  tensor(28.9502, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.4989,  4.4867,  9.6682,  2.3952], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  92000 \n",
      "loss:  tensor(20.1621, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([4.8518, 3.0901, 4.7376, 6.0115], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  93000 \n",
      "loss:  tensor(7.8316, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([2.8039, 4.7260, 1.0355, 1.2385], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  94000 \n",
      "loss:  tensor(7.9107, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-3.3147, -4.2272,  0.2732, -0.6467], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  95000 \n",
      "loss:  tensor(297.0201, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ -8.5481, -12.7326, -25.2695, -16.7297], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  96000 \n",
      "loss:  tensor(46.0184, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.0159, 6.7504, 8.6601, 6.2266], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  97000 \n",
      "loss:  tensor(8.6248, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-4.4735,  2.3925,  2.8980,  0.3963], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  98000 \n",
      "loss:  tensor(20.1431, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([5.1430, 2.6365, 4.5943, 6.1052], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  99000 \n",
      "loss:  tensor(54.0413, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.8141, 7.5583, 8.3711, 7.5216], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  100000 \n",
      "loss:  tensor(235.8227, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-10.6008, -10.8079, -20.9894, -15.5393], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  101000 \n",
      "loss:  tensor(18.8918, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([5.2489, 2.6221, 4.2277, 5.8236], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  102000 \n",
      "loss:  tensor(11.8691, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.1088, -1.3384, -4.2364, -4.1486], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  103000 \n",
      "loss:  tensor(175.6832, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ -9.4517,  -5.6880, -19.3042, -13.4359], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  104000 \n",
      "loss:  tensor(36.9255, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([7.0232, 4.4888, 6.2629, 7.2453], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  105000 \n",
      "loss:  tensor(138.5357, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 9.5200, 10.1819, 14.2373, 13.5356], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  106000 \n",
      "loss:  tensor(17.7777, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-3.3132, -5.6385, -4.6682, -1.5590], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  107000 \n",
      "loss:  tensor(50.7699, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-8.8633,  1.0848, -7.1277, -7.5171], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  108000 \n",
      "loss:  tensor(2.3861, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.1154, -2.5097,  1.5801,  1.8578], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iteration:  109000 \n",
      "loss:  tensor(17.8937, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-4.6372, -5.8800, -3.3185, -1.1176], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  110000 \n",
      "loss:  tensor(15.4336, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([5.6803, 4.1721, 0.3570, 4.4546], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  111000 \n",
      "loss:  tensor(17.6613, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-4.3449, -3.7506, -4.5967, -3.0708], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  112000 \n",
      "loss:  tensor(44.7386, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.8396, 7.4430, 7.1237, 6.1018], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  113000 \n",
      "loss:  tensor(1.5117, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.3330, -2.2089,  0.9604,  1.3665], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  114000 \n",
      "loss:  tensor(44.0543, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-7.9434, -5.8509, -6.5808, -4.9649], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  115000 \n",
      "loss:  tensor(48.8112, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 2.1266, 11.1040,  8.1967,  1.4860], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  116000 \n",
      "loss:  tensor(20.1418, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([4.9232, 3.4322, 4.8914, 5.5414], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  117000 \n",
      "loss:  tensor(104.7880, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-12.1991,  -9.4289, -10.5707,  -7.3481], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  118000 \n",
      "loss:  tensor(45.9765, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-6.5938, -6.5938, -8.3480, -4.2212], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  119000 \n",
      "loss:  tensor(24.2789, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([4.5994, 5.1244, 6.1229, 4.4945], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  120000 \n",
      "loss:  tensor(88.1836, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 5.4786,  5.0367, 12.1521, 13.2342], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  121000 \n",
      "loss:  tensor(139.1661, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-10.7995,  -8.7759, -15.2124, -10.4719], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  122000 \n",
      "loss:  tensor(14.5291, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([0.4680, 5.9741, 4.6795, 0.4429], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  123000 \n",
      "loss:  tensor(34.8498, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([3.9713, 9.4057, 6.0507, 4.0450], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  124000 \n",
      "loss:  tensor(8.8620, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([1.5149, 3.2705, 4.3487, 2.8832], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  125000 \n",
      "loss:  tensor(32.6462, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.0102, 2.8131, 6.9354, 7.2007], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  126000 \n",
      "loss:  tensor(14.3314, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 5.9361,  5.1126, -2.2473, -0.3522], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  127000 \n",
      "loss:  tensor(59.8422, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([8.1394, 5.8821, 8.8241, 8.7880], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  128000 \n",
      "loss:  tensor(6.7882, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-3.7800,  0.3983,  3.5449,  0.6275], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  129000 \n",
      "loss:  tensor(2.0078, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.0652, -2.4939, -0.2942,  0.2317], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  130000 \n",
      "loss:  tensor(1.9064, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([0.5725, 1.8598, 1.8399, 0.3265], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  131000 \n",
      "loss:  tensor(9.2096, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.5122, -5.6421, -2.1758,  0.9042], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  132000 \n",
      "loss:  tensor(26.5312, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([5.2392, 6.3636, 4.8194, 4.8670], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  133000 \n",
      "loss:  tensor(4.0278, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-2.2277, -2.2846,  2.3943,  1.4436], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  134000 \n",
      "loss:  tensor(4.1014, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 2.8281,  2.7435, -0.9373,  1.0442], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  135000 \n",
      "loss:  tensor(51.4407, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([7.0285, 7.0689, 8.3126, 7.1068], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  136000 \n",
      "loss:  tensor(7.1477, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.3904,  1.2242,  4.9365,  1.8883], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  137000 \n",
      "loss:  tensor(46.0769, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 2.5460, 10.2744,  8.4946,  1.3233], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  138000 \n",
      "loss:  tensor(99.9925, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ -2.8826, -10.5275, -14.7951,  -6.8700], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  139000 \n",
      "loss:  tensor(29.0522, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-4.1286, -6.1717, -5.7300, -3.9726], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  140000 \n",
      "loss:  tensor(38.9584, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.7253, 5.9370, 6.4156, 6.8478], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  141000 \n",
      "loss:  tensor(1.9655, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 2.0210,  1.0810, -1.0220,  2.2507], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  142000 \n",
      "loss:  tensor(4.7831, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-3.0214,  0.3925, -1.9712, -1.4422], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  143000 \n",
      "loss:  tensor(5.4546, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 1.6092, -2.1759, -2.3751, -1.9754], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  144000 \n",
      "loss:  tensor(43.7652, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([7.2856, 6.3087, 6.2978, 7.5206], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  145000 \n",
      "loss:  tensor(12.5240, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([3.8143, 2.6838, 3.6602, 4.8662], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  146000 \n",
      "loss:  tensor(45.4734, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([0.1876, 9.0673, 9.7730, 3.0327], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  147000 \n",
      "loss:  tensor(39.5777, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.2613, 4.2550, 7.7893, 7.3505], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  148000 \n",
      "loss:  tensor(38.1156, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([7.6487, 3.4439, 5.1054, 8.4856], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  149000 \n",
      "loss:  tensor(165.4177, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([10.7416, 12.2218, 16.3694, 12.3561], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  150000 \n",
      "loss:  tensor(4.9327, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.9867, -0.2467, -1.7839, -2.9388], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  151000 \n",
      "loss:  tensor(9.9667, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.0958, -5.3643, -3.2569,  0.3114], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  152000 \n",
      "loss:  tensor(55.6388, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 2.0315, 11.4118,  9.3914,  0.9803], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  153000 \n",
      "loss:  tensor(20.5921, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.4457,  7.5900,  4.7808, -0.3063], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  154000 \n",
      "loss:  tensor(11.6012, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-5.5355, -3.8193,  0.2985, -0.0422], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  155000 \n",
      "loss:  tensor(5.4140, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.6487, -4.0631, -0.5055, -0.4029], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  156000 \n",
      "loss:  tensor(30.9029, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([0.2541, 5.1104, 9.4446, 3.8688], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  157000 \n",
      "loss:  tensor(44.5076, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([7.3257, 6.4048, 6.6153, 7.2912], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  158000 \n",
      "loss:  tensor(11.9836, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-3.4618, -4.4972, -2.6013, -1.9931], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  159000 \n",
      "loss:  tensor(12.0013, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([3.6739, 5.3020, 1.4402, 3.0790], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  160000 \n",
      "loss:  tensor(19.5282, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.2814, 3.3466, 3.1560, 5.1830], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  161000 \n",
      "loss:  tensor(51.0440, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-5.6358, -6.6440, -9.0752, -5.7759], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  162000 \n",
      "loss:  tensor(4.1192, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.2108, -2.3862, -1.1091, -1.8437], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  163000 \n",
      "loss:  tensor(58.5505, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([8.1896, 7.0794, 7.7544, 8.5422], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iteration:  164000 \n",
      "loss:  tensor(39.7196, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.3893,  3.6690,  7.9693, 10.0419], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  165000 \n",
      "loss:  tensor(33.4851, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 1.0705, -5.5700, -8.0833, -5.0357], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  166000 \n",
      "loss:  tensor(80.9957, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 7.7091,  5.5948, 10.9768, 11.6189], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  167000 \n",
      "loss:  tensor(42.0431, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([7.8097, 4.2844, 6.0728, 8.2073], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  168000 \n",
      "loss:  tensor(44.2799, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.5596, 6.7699, 7.1599, 7.0825], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  169000 \n",
      "loss:  tensor(13.8370, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 2.4407, -3.6679, -4.9624, -2.3634], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  170000 \n",
      "loss:  tensor(145.0559, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-13.0438, -10.3564, -13.3200, -10.1983], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  171000 \n",
      "loss:  tensor(199.8194, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([10.4909, 11.2966, 19.2681, 14.7965], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  172000 \n",
      "loss:  tensor(5.4607, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-3.4812,  1.5076, -0.8144, -1.6053], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  173000 \n",
      "loss:  tensor(34.2443, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.1360, 6.0553, 6.2275, 5.8864], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  174000 \n",
      "loss:  tensor(80.4028, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ -9.6376,  -3.4204, -10.1274,  -9.6988], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  175000 \n",
      "loss:  tensor(29.8780, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([4.3527, 6.8269, 6.5915, 4.2422], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  176000 \n",
      "loss:  tensor(257.6281, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 8.1721, 11.6556, 22.9151, 18.4005], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  177000 \n",
      "loss:  tensor(86.8205, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 6.8830,  0.5490, 10.3667, 14.8613], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  178000 \n",
      "loss:  tensor(38.8134, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([4.9293, 9.4608, 6.2943, 4.4443], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  179000 \n",
      "loss:  tensor(12.4048, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([4.3449, 3.7392, 2.7577, 4.0257], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  180000 \n",
      "loss:  tensor(10.3211, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 1.4934, -3.0227, -4.5528, -2.0314], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  181000 \n",
      "loss:  tensor(11.4823, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([1.4097, 4.3516, 4.9468, 1.7315], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  182000 \n",
      "loss:  tensor(20.3587, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([5.5534, 3.9398, 4.0337, 5.3361], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  183000 \n",
      "loss:  tensor(26.6813, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.3997, -2.7781, -8.0624, -4.8177], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  184000 \n",
      "loss:  tensor(2.9898, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 1.8124,  0.6344, -2.8161,  0.4154], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  185000 \n",
      "loss:  tensor(0.8770, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.6488, -1.6853,  0.4950,  0.9582], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  186000 \n",
      "loss:  tensor(21.0290, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 1.7861, -3.7383, -6.4214, -4.0712], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  187000 \n",
      "loss:  tensor(81.6336, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 8.2544,  7.0157, 10.5542, 10.8888], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  188000 \n",
      "loss:  tensor(41.5118, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([7.4305, 5.2834, 6.8714, 6.9754], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  189000 \n",
      "loss:  tensor(2.3198, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 2.3202,  0.1913, -1.9628,  1.0805], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  190000 \n",
      "loss:  tensor(26.3096, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-2.5513, -7.5815, -6.2578, -0.4456], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  191000 \n",
      "loss:  tensor(34.0262, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.6897, 4.0028, 6.0287, 7.2439], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  192000 \n",
      "loss:  tensor(4.6817, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-3.6424, -1.7274,  1.3294,  0.1579], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  193000 \n",
      "loss:  tensor(140.0149, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 7.7514,  9.7852, 16.1377, 12.9916], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  194000 \n",
      "loss:  tensor(21.4769, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([0.0937, 5.8598, 6.8286, 3.2205], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  195000 \n",
      "loss:  tensor(6.9343, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([3.6432, 3.3895, 0.1208, 2.7208], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  196000 \n",
      "loss:  tensor(179.7291, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 7.6313,  5.3102, 17.5210, 19.0415], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  197000 \n",
      "loss:  tensor(4.9636, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([0.6059, 2.2458, 3.0301, 3.2940], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  198000 \n",
      "loss:  tensor(46.4777, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-3.7964, -8.7322, -8.2207, -4.2600], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  199000 \n",
      "loss:  tensor(39.9808, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.3576, 8.9457, 5.0613, 4.7231], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  200000 \n",
      "loss:  tensor(35.5275, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([5.9691, 7.1725, 6.2267, 5.0327], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  201000 \n",
      "loss:  tensor(274.4985, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 8.6452, 13.4040, 24.1011, 17.2088], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  202000 \n",
      "loss:  tensor(10.4215, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-3.8089, -2.7284, -2.4143, -2.7290], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  203000 \n",
      "loss:  tensor(70.3705, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 7.1151, 10.8533,  9.6358,  6.3969], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  204000 \n",
      "loss:  tensor(15.3070, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-4.6406, -5.2538, -2.8724, -0.9594], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  205000 \n",
      "loss:  tensor(35.4067, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-5.0615, -6.3415, -7.3867, -3.6075], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  206000 \n",
      "loss:  tensor(17.8118, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 2.2795, -4.4682, -5.4808, -3.0059], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  207000 \n",
      "loss:  tensor(123.0380, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ -9.9712,  -5.8973, -14.4231, -11.2444], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  208000 \n",
      "loss:  tensor(1.4146, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 0.1889, -1.3273, -0.4715, -0.9075], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  209000 \n",
      "loss:  tensor(8.0660, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.5418, -2.5379, -3.6589, -2.1715], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  210000 \n",
      "loss:  tensor(29.6658, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-3.1746, -6.5179, -7.1565, -2.8584], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  211000 \n",
      "loss:  tensor(50.2090, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.9806, 7.3172, 8.1318, 6.6957], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  212000 \n",
      "loss:  tensor(2.2725, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([2.2986, 0.8833, 1.6216, 1.6298], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  213000 \n",
      "loss:  tensor(1.3266, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([1.2517, 1.6200, 1.0261, 1.2489], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  214000 \n",
      "loss:  tensor(4.2217, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 1.8417,  0.6283, -2.4900, -1.6269], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  215000 \n",
      "loss:  tensor(152.5350, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ -7.6124, -10.5204, -18.0969,  -9.6777], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  216000 \n",
      "loss:  tensor(28.6695, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.8269, 2.9003, 5.0158, 6.8737], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  217000 \n",
      "loss:  tensor(6.6105, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.1001, -4.2452, -2.5051, -0.4610], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  218000 \n",
      "loss:  tensor(6.6137, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([2.7378, 3.9605, 1.5268, 1.9708], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iteration:  219000 \n",
      "loss:  tensor(43.5195, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.8822, 4.8894, 7.1791, 8.1601], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  220000 \n",
      "loss:  tensor(6.1594, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.7693, -0.2837, -4.7148, -0.3175], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  221000 \n",
      "loss:  tensor(144.5624, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ -9.3674,  -8.1560, -16.7136, -11.0265], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  222000 \n",
      "loss:  tensor(147.2565, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ -7.6579,  -8.4142, -17.8207, -10.9167], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  223000 \n",
      "loss:  tensor(12.9280, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-4.2481, -4.4588, -2.2636, -1.9430], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  224000 \n",
      "loss:  tensor(4.6591, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 3.1373,  1.5803, -2.4752,  1.4123], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  225000 \n",
      "loss:  tensor(31.6583, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([7.6963, 2.1308, 4.1434, 7.7596], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  226000 \n",
      "loss:  tensor(234.2476, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 6.6992,  7.3493, 21.5760, 19.6208], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  227000 \n",
      "loss:  tensor(48.3310, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([7.5692, 8.4931, 5.9934, 6.2894], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  228000 \n",
      "loss:  tensor(36.6631, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([5.0860, 6.7124, 7.2790, 5.7692], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  229000 \n",
      "loss:  tensor(9.0685, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 1.8850,  4.4437,  3.0513, -0.9140], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  230000 \n",
      "loss:  tensor(4.2361, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.5850, -2.6539, -2.0910, -0.0682], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  231000 \n",
      "loss:  tensor(10.1785, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-4.3014, -4.4951, -1.0135,  0.0106], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  232000 \n",
      "loss:  tensor(6.2809, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-3.9147,  0.7116, -1.5693, -1.6134], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  233000 \n",
      "loss:  tensor(4.2555, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.6571,  1.6326,  3.2312,  2.0815], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  234000 \n",
      "loss:  tensor(5.3354, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-2.6482,  1.2398,  3.3716, -0.1932], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  235000 \n",
      "loss:  tensor(39.3782, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.4927,  6.1861, 10.2844,  4.3537], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  236000 \n",
      "loss:  tensor(11.5862, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-3.4644, -5.1784, -2.2656, -0.5474], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  237000 \n",
      "loss:  tensor(22.7567, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.4524, 2.2889, 3.0452, 6.9061], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  238000 \n",
      "loss:  tensor(5.8885, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 0.7998, -1.0953, -2.9642, -2.5956], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  239000 \n",
      "loss:  tensor(10.3022, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-5.6461,  1.6722,  2.3218, -0.0691], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  240000 \n",
      "loss:  tensor(44.1224, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-7.0219, -4.7051, -7.4282, -6.0617], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  241000 \n",
      "loss:  tensor(20.8887, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([5.2878, 3.4748, 4.6884, 5.6410], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  242000 \n",
      "loss:  tensor(3.9856, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 1.7872,  3.4274, -0.3210,  1.9476], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  243000 \n",
      "loss:  tensor(25.0819, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([5.4964, 3.6558, 5.0473, 6.5926], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  244000 \n",
      "loss:  tensor(5.4328, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([0.7049, 4.5386, 0.7096, 0.6370], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  245000 \n",
      "loss:  tensor(19.3022, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 0.4997, -2.3629, -5.4535, -5.4526], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  246000 \n",
      "loss:  tensor(35.0391, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([7.3237, 3.6831, 5.2946, 7.7024], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  247000 \n",
      "loss:  tensor(10.3237, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-3.3928,  1.8695,  5.0752,  1.7284], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  248000 \n",
      "loss:  tensor(6.8883, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-4.9187, -1.2010,  0.8115, -0.1218], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  249000 \n",
      "loss:  tensor(86.3656, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ -4.5508,  -7.0345, -13.9238,  -8.0220], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  250000 \n",
      "loss:  tensor(21.5380, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.3179, 2.4303, 2.9589, 6.6191], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  251000 \n",
      "loss:  tensor(16.1033, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([3.6909, 5.9602, 3.3136, 3.0704], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  252000 \n",
      "loss:  tensor(18.4822, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([3.7872, 5.9652, 3.7891, 4.1055], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  253000 \n",
      "loss:  tensor(27.1873, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([8.3663, 6.7444, 0.7587, 2.2763], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  254000 \n",
      "loss:  tensor(36.3525, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.6515, -6.3988, -8.3933, -4.7961], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  255000 \n",
      "loss:  tensor(17.1626, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([4.2190, 2.3048, 5.0745, 5.4483], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  256000 \n",
      "loss:  tensor(10.1289, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-2.9197, -4.2223, -3.1247, -1.0974], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  257000 \n",
      "loss:  tensor(3.0385, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 2.4598,  0.4290, -1.9472,  2.4588], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  258000 \n",
      "loss:  tensor(28.7996, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-2.6251, -7.1386, -6.7292, -2.4735], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  259000 \n",
      "loss:  tensor(4.2435, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 0.7273, -2.7946, -2.3420, -0.7749], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  260000 \n",
      "loss:  tensor(5.2670, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-3.6992,  0.0945,  1.7962,  3.0368], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  261000 \n",
      "loss:  tensor(20.8580, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-2.3674, -5.8191, -5.9967, -1.8293], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  262000 \n",
      "loss:  tensor(13.0898, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.4728,  6.4835,  1.1023, -1.9808], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  263000 \n",
      "loss:  tensor(16.7724, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([4.0393, 5.1647, 4.2246, 3.5005], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  264000 \n",
      "loss:  tensor(32.3431, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([5.5639, 3.7042, 7.1401, 6.8062], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  265000 \n",
      "loss:  tensor(13.3487, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.2846,  6.6692,  2.2989, -0.8844], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  266000 \n",
      "loss:  tensor(52.7892, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([7.3945, 8.2158, 7.2969, 6.9778], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  267000 \n",
      "loss:  tensor(15.3195, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([4.9675, 4.0598, 2.8148, 4.4925], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  268000 \n",
      "loss:  tensor(8.3351, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-2.5831, -4.6569, -2.0324,  0.0780], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  269000 \n",
      "loss:  tensor(24.2036, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.4456, 3.6957, 3.8952, 6.1418], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  270000 \n",
      "loss:  tensor(11.1613, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-4.6105, -4.0625, -0.7104, -1.5259], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  271000 \n",
      "loss:  tensor(72.9350, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 0.9469,  1.0697,  9.6140, 14.0770], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  272000 \n",
      "loss:  tensor(25.6770, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([5.5567, 5.4110, 4.7573, 5.4633], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  273000 \n",
      "loss:  tensor(26.5853, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.4760, 3.8727, 4.4544, 6.4372], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iteration:  274000 \n",
      "loss:  tensor(12.4540, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.2735, -5.4481, -3.9243, -0.7641], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  275000 \n",
      "loss:  tensor(3.9381, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 0.9416,  2.7724,  2.4112, -0.1685], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  276000 \n",
      "loss:  tensor(3.9977, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.7598, -3.1087, -0.6960, -0.5942], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  277000 \n",
      "loss:  tensor(43.5908, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([5.2629, 2.1733, 8.1973, 9.6456], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  278000 \n",
      "loss:  tensor(24.0806, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.2656,  8.4828,  4.7752, -0.2215], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  279000 \n",
      "loss:  tensor(2.8452, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.4248,  2.1981,  2.2161,  2.2073], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  280000 \n",
      "loss:  tensor(4.1161, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 2.8190,  2.1627, -1.9490,  1.2048], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  281000 \n",
      "loss:  tensor(42.6605, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([7.4488, 8.0042, 5.1146, 5.9930], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  282000 \n",
      "loss:  tensor(32.7180, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-5.9744, -6.4107, -5.3673, -4.0273], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  283000 \n",
      "loss:  tensor(23.0405, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-3.9683, -4.6738, -5.8653, -3.4910], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  284000 \n",
      "loss:  tensor(48.9058, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 5.8966, 10.1644,  7.0514,  5.2102], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  285000 \n",
      "loss:  tensor(1.7162, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.1419,  1.3843,  2.0877,  1.7550], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  286000 \n",
      "loss:  tensor(6.3609, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([2.3937, 4.4111, 0.2609, 1.4332], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  287000 \n",
      "loss:  tensor(41.1646, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-2.4519, -3.5526, -8.8095, -7.2715], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  288000 \n",
      "loss:  tensor(39.0707, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-7.2857, -7.2186, -5.0560, -4.0528], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  289000 \n",
      "loss:  tensor(11.8415, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-2.2848, -4.0261, -3.8940, -1.4087], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  290000 \n",
      "loss:  tensor(15.0157, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-5.8523, -2.6285, -3.6574, -1.3511], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  291000 \n",
      "loss:  tensor(33.5871, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-4.5785, -6.7361, -6.2286, -4.4051], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  292000 \n",
      "loss:  tensor(95.5827, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ -8.8070,  -7.7144, -12.2932,  -8.7022], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  293000 \n",
      "loss:  tensor(32.4519, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.1681, 4.3443, 6.1769, 6.8936], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  294000 \n",
      "loss:  tensor(23.2993, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([5.3956, 3.1859, 5.5170, 5.8475], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  295000 \n",
      "loss:  tensor(1.3876, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.0910, -0.8161,  1.9097,  1.2171], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  296000 \n",
      "loss:  tensor(20.3234, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([4.4374, 4.8284, 4.9702, 4.6860], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  297000 \n",
      "loss:  tensor(2.3719, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 0.5212,  2.8791, -0.3075,  0.0878], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  298000 \n",
      "loss:  tensor(16.6002, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([5.3388, 2.4906, 3.0615, 5.7245], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  299000 \n",
      "loss:  tensor(2.4845, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.8237, -2.3717, -1.6701,  0.0808], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  300000 \n",
      "loss:  tensor(25.4741, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([5.8451, 3.2367, 5.0664, 6.6201], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  301000 \n",
      "loss:  tensor(12.1813, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 2.0188,  7.6640,  0.0094, -0.4903], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  302000 \n",
      "loss:  tensor(2.0786, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.8115, -1.8069, -1.0874, -0.1830], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  303000 \n",
      "loss:  tensor(17.6821, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([4.3902, 3.6026, 4.6726, 5.0794], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  304000 \n",
      "loss:  tensor(19.2990, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.0140, 2.3599, 2.6727, 6.3212], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  305000 \n",
      "loss:  tensor(41.4448, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.3141, 6.7311, 7.1800, 6.3901], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  306000 \n",
      "loss:  tensor(2.5546, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.0185, -2.9688,  0.4550,  0.5992], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  307000 \n",
      "loss:  tensor(28.8977, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.5446, 5.1365, 4.0564, 6.4701], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  308000 \n",
      "loss:  tensor(2.1882, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-0.9149, -1.8645,  2.1062,  0.9455], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  309000 \n",
      "loss:  tensor(30.0088, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([4.8287, 8.7288, 5.4388, 2.7212], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  310000 \n",
      "loss:  tensor(44.2040, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.9314, -7.5278, -8.7488, -4.6238], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  311000 \n",
      "loss:  tensor(15.5595, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-2.3087, -4.1355, -4.5416, -3.0159], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  312000 \n",
      "loss:  tensor(116.2982, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ -8.2818, -10.0606, -14.0571,  -8.8888], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  313000 \n",
      "loss:  tensor(20.8567, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.9013, -6.9788, -4.9925, -1.4866], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  314000 \n",
      "loss:  tensor(18.9417, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.7119,  4.2193,  7.1626,  2.9315], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  315000 \n",
      "loss:  tensor(27.0101, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([6.7360, 4.5177, 3.6109, 6.4054], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  316000 \n",
      "loss:  tensor(16.6589, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([5.1894, 2.8918, 3.6431, 5.2510], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  317000 \n",
      "loss:  tensor(14.7025, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([4.9672, 2.8719, 3.2759, 4.8932], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  318000 \n",
      "loss:  tensor(39.6992, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([7.5812, 4.1172, 5.7102, 8.1948], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  319000 \n",
      "loss:  tensor(29.4492, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([7.7763, 7.6151, 2.4551, 2.7456], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  320000 \n",
      "loss:  tensor(12.2028, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-2.9088, -4.6968, -2.0572, -2.7494], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  321000 \n",
      "loss:  tensor(127.5094, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ -6.1713,  -8.2521, -15.4701, -11.8270], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  322000 \n",
      "loss:  tensor(67.9992, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 4.6599,  1.6465,  8.9295, 13.9551], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  323000 \n",
      "loss:  tensor(44.0469, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-5.6365, -7.3275, -8.2284, -3.7979], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  324000 \n",
      "loss:  tensor(73.4076, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ -0.8134,  -8.7488, -12.2328,  -7.1723], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  325000 \n",
      "loss:  tensor(19.0803, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([4.2072, 2.7552, 5.4392, 5.6309], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  326000 \n",
      "loss:  tensor(68.0303, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-9.3267, -1.5610, -8.8247, -9.2383], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  327000 \n",
      "loss:  tensor(19.2477, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([4.5487, 5.1654, 4.4083, 4.1915], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  328000 \n",
      "loss:  tensor(24.4781, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([5.2394, 4.8151, 4.9725, 5.7488], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iteration:  329000 \n",
      "loss:  tensor(10.2539, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([3.6727, 2.5665, 2.6794, 4.7095], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  330000 \n",
      "loss:  tensor(5.5829, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-2.8123,  1.1282,  3.6262,  1.0179], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  331000 \n",
      "loss:  tensor(2.5508, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 0.7402,  3.0213, -0.0503,  0.2759], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  332000 \n",
      "loss:  tensor(20.9824, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([5.4941, 4.8145, 3.5743, 5.2177], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  333000 \n",
      "loss:  tensor(50.0778, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([  0.4278,  -5.9514, -11.3489,  -4.9927], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  334000 \n",
      "loss:  tensor(45.8650, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([7.1064, 8.5658, 5.8996, 5.9782], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  335000 \n",
      "loss:  tensor(116.9135, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ -2.8850, -10.1722, -16.4392,  -8.2526], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  336000 \n",
      "loss:  tensor(14.9042, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-6.5637, -0.4183, -0.8586, -2.9525], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  337000 \n",
      "loss:  tensor(55.2698, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ -1.8561,  -8.2423, -10.3813,  -5.4751], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  338000 \n",
      "loss:  tensor(1.0817, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([-1.0640,  0.9331, -0.6164, -0.3942], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  339000 \n",
      "loss:  tensor(15.5485, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([4.3511, 2.8056, 4.3205, 5.0895], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "iteration:  340000 \n",
      "loss:  tensor(8.8755, grad_fn=<MseLossBackward>) \n",
      "\tOutput:\n",
      " tensor([ 0.6232, -1.1391, -3.1345, -3.8981], grad_fn=<AddBackward0>)\n",
      "Learning time: \n",
      "\t 131.90827059745789\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "while ((loss > 0.01) and (lossDuplicationCounter<10)):\n",
    "    a=r(0, (len(contents)/15-1))\n",
    "    chars = torch.tensor(contents[(a*15):(a*15+14)])\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    out = net(chars)\n",
    "    if (contents[a*14+15]=='Marcin'):\n",
    "        target = torch.tensor([1., 0., 0., 0.])\n",
    "    elif (contents[a*14+15]=='Bartek'):\n",
    "        target = torch.tensor([0., 1., 0., 0.])\n",
    "    elif (contents[a*14+15]=='Maciek'):\n",
    "        target = torch.tensor([0., 0., 1., 0.,])\n",
    "    else:\n",
    "        target = torch.tensor([0., 0., 0., 1.,])\n",
    "    loss = criterion(out, target)\n",
    "    if prevloss == loss:\n",
    "        lossDuplicationCounter +=1\n",
    "        print('loss duplicate #', lossDuplicationCounter)\n",
    "    else:\n",
    "        lossDuplicationCounter = 0\n",
    "    prevloss = loss\n",
    "    loss.backward(retain_graph=True)\n",
    "    #loss.backward()\n",
    "    optimizer.step()    # Does the update\n",
    "    if i%1000==0:\n",
    "        print(\"\\n\\niteration: \", i, \"\\nloss: \", loss, '\\n\\tOutput:\\n', out)\n",
    "    i+=1\n",
    "print(\"Learning time: \\n\\t\", time.time()-start)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0542, -0.0643, -0.0803,  0.9226], grad_fn=<AddBackward0>)\n",
      "340407 tensor(0.0049, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(out)\n",
    "print('\\n', i, '\\n', out, '\\n', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Network. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(net, \"net.dat\")\n",
    "torch.save(net.state_dict(), \"netstate.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haba = torch.load(\"net.dat\")\n",
    "baba = Network()\n",
    "baba.load_state_dict(torch.load(\"netstate.dat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
