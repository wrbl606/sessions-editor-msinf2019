{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "path = \"./../dist/char*.txt\"\n",
    "contents=[]\n",
    "for filename in glob.glob(path):\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            contents.append(line.strip('\\n'))\n",
    "print(len(contents))\n",
    "i=0\n",
    "while (i<len(contents)-1):\n",
    "    contents[i]=float(contents[i])\n",
    "    i+=1\n",
    "    if ((i+1)%15==0):\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint as r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=14, out_features=14)\n",
    "        self.fc2 = nn.Linear(in_features=14, out_features=4)\n",
    "        #self.out = nn.Linear(in_features=14, out_features = 4, bias=True)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        #1st layer\n",
    "        t = self.fc1(t)\n",
    "        #2nd layer\n",
    "        t = self.fc2(t)\n",
    "\n",
    "        #t = F.softmax(t)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Network()\n",
    "params=list(net.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "net.zero_grad()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0000000001)\n",
    "lossDuplicationCounter = 0\n",
    "prevloss=0\n",
    "loss = 4\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iteration:  0 \n",
      "Loss:  20805842. \n",
      "Output:  [-6805.1733, -5400.6064, -1745.0739, -2167.2136],\n",
      " \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  1000 \n",
      "Loss:  35397.9609 \n",
      "Output:  [  51.9023, -136.5978, -219.7746,  267.7013] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  2000 \n",
      "Loss:  1228.0507 \n",
      "Output:  [ 12.6701, -58.0985, -22.1364,  28.9991] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  3000 \n",
      "Loss:  4960.6523 \n",
      "Output:  [ 15.2907, -76.6994, -54.3176, 103.0592] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  4000 \n",
      "Loss:  9911.8164 \n",
      "Output:  [ 28.8062, -90.9083, -92.9538, 147.3969] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  5000 \n",
      "Loss:  396041.1250 \n",
      "Output:  [ -92.2964,  511.3264,  618.6121, -965.7880] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  6000 \n",
      "Loss:  772.0061 \n",
      "Output:  [  3.1337, -29.2497, -28.0656,  38.8811] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  7000 \n",
      "Loss:  563.7755 \n",
      "Output:  [  5.8037, -33.2869, -21.4543,  24.6820] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  8000 \n",
      "Loss:  49135.8281 \n",
      "Output:  [  61.8116, -212.8455, -219.3112,  316.1540] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  9000 \n",
      "Loss:  1026.1201 \n",
      "Output:  [ 8.2624,  0.6549, -7.1689, 64.1220] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  10000 \n",
      "Loss:  43446.8516 \n",
      "Output:  [  36.4908, -211.5937, -195.7301,  298.2439] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  11000 \n",
      "Loss:  8650.3232 \n",
      "Output:  [  17.1624, -112.2575,  -83.2985,  120.8253] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  12000 \n",
      "Loss:  2001.6198 \n",
      "Output:  [ -5.3128,  53.0326,  35.9339, -62.8126] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  13000 \n",
      "Loss:  1091.3168 \n",
      "Output:  [ 1.9257, -3.8975, -4.6511, 66.7627] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  14000 \n",
      "Loss:  351.9114 \n",
      "Output:  [ -2.9970, -33.1288, -14.2717,   8.2415] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  15000 \n",
      "Loss:  754.6707 \n",
      "Output:  [-0.9555,  9.8028,  7.7349, 53.6698] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  16000 \n",
      "Loss:  635.4916 \n",
      "Output:  [ 1.3331, -9.8360, -4.6694, 49.2271] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  17000 \n",
      "Loss:  31.5505 \n",
      "Output:  [-9.1575, -0.0948,  6.3660, -3.6794] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  18000 \n",
      "Loss:  234.4582 \n",
      "Output:  [  4.1062, -18.1895, -13.8425,  20.9624] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  19000 \n",
      "Loss:  817.2250 \n",
      "Output:  [-0.9325, 10.1620,  9.2755, 56.4863] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  20000 \n",
      "Loss:  1069.5099 \n",
      "Output:  [ 3.2155, 14.0370,  9.1649, 63.3541] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  21000 \n",
      "Loss:  2459.2981 \n",
      "Output:  [  0.1102, -68.7093, -40.8752,  57.5066] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  22000 \n",
      "Loss:  50.7619 \n",
      "Output:  [ 1.2899, -9.9372, -7.1257, -5.5666] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  23000 \n",
      "Loss:  8033.9370 \n",
      "Output:  [-10.1207, -94.6700, -82.1515, 128.7577] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  24000 \n",
      "Loss:  1376.9482 \n",
      "Output:  [ -5.3256,  51.5957,  27.3714, -46.5866] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  25000 \n",
      "Loss:  215.9358 \n",
      "Output:  [ 2.5473,  1.3579,  5.9967, 28.8174] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  26000 \n",
      "Loss:  1280.3994 \n",
      "Output:  [  3.2943, -52.9491, -27.2687,  38.1662] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  27000 \n",
      "Loss:  295.7205 \n",
      "Output:  [ -5.7327, -18.6333,  -4.4968, -27.7957] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  28000 \n",
      "Loss:  11.6941 \n",
      "Output:  [ 2.0149, -4.9140, -2.3029,  4.0368] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  29000 \n",
      "Loss:  12.0786 \n",
      "Output:  [ 1.3490, -5.5102, -3.9855,  1.4980] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  30000 \n",
      "Loss:  3281.8186 \n",
      "Output:  [ -8.7374, -72.6948, -37.1134,  80.9312] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  31000 \n",
      "Loss:  3292.1035 \n",
      "Output:  [  7.3529, -74.8054, -43.2887,  75.2216] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  32000 \n",
      "Loss:  398.8279 \n",
      "Output:  [ -1.2826,  31.5412,  15.0374, -20.0441] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  33000 \n",
      "Loss:  64.3417 \n",
      "Output:  [ 2.4310, 13.9428,  4.8621, -6.4915] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  34000 \n",
      "Loss:  697.0829 \n",
      "Output:  [  3.8389, -30.7517, -19.6379,  38.0652] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  35000 \n",
      "Loss:  285.6960 \n",
      "Output:  [ -0.9418, -24.6590, -12.1525,  18.9959] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  36000 \n",
      "Loss:  461.3215 \n",
      "Output:  [ -2.7379, -34.2902, -15.1799,  20.0047] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  37000 \n",
      "Loss:  194.3824 \n",
      "Output:  [ -1.1012, -23.3965, -11.5802,  10.7376] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  38000 \n",
      "Loss:  40.0262 \n",
      "Output:  [-2.3998,  9.9439,  5.7581, -5.7292] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  39000 \n",
      "Loss:  1.4673 \n",
      "Output:  [ 0.6336, -0.3089, -1.3415,  2.8902] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  40000 \n",
      "Loss:  52.4394 \n",
      "Output:  [  3.5346,  -2.2255,  -0.0998, -12.8673] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  41000 \n",
      "Loss:  74.8147 \n",
      "Output:  [ -1.6880, -14.0352,  -7.5651,  -6.1495] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  42000 \n",
      "Loss:  812.1818 \n",
      "Output:  [  1.3485, -42.5345, -21.8356,  31.9988] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  43000 \n",
      "Loss:  159.2086 \n",
      "Output:  [ 1.8612,  8.9226, 10.5013, 21.5287] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  44000 \n",
      "Loss:  333.0769 \n",
      "Output:  [ -1.1186, -31.0567, -17.3361,   1.6988] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  45000 \n",
      "Loss:  20.8014 \n",
      "Output:  [ 1.4714, -8.1337, -2.7780, -0.7815] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  46000 \n",
      "Loss:  2737.4946 \n",
      "Output:  [  17.9122,   22.7982,   -0.9099, -100.5272] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  47000 \n",
      "Loss:  73.2964 \n",
      "Output:  [-2.1652,  0.0681,  5.5040, 15.9018] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  48000 \n",
      "Loss:  144.4302 \n",
      "Output:  [ -0.9946, -18.8031,  -8.7302,  10.4093] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  49000 \n",
      "Loss:  176.5125 \n",
      "Output:  [ -1.9411, -22.1509, -10.7297,   9.5715] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  50000 \n",
      "Loss:  49.5432 \n",
      "Output:  [ 1.0535, 12.8706,  4.1292, -6.2531] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  51000 \n",
      "Loss:  51.4569 \n",
      "Output:  [ -3.4373, -10.3811,  -7.6183,  -3.4598] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  52000 \n",
      "Loss:  9.5219 \n",
      "Output:  [-1.2703, -0.0595, -2.5549, -4.4720] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  53000 \n",
      "Loss:  83.5317 \n",
      "Output:  [ 0.5427, 17.1487,  6.2742, -3.4547] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  54000 \n",
      "Loss:  195.7115 \n",
      "Output:  [ -3.8565, -23.7080, -11.0929,   5.8680] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  55000 \n",
      "Loss:  122.0620 \n",
      "Output:  [-0.5990,  6.8344,  8.6480, 19.5624] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  56000 \n",
      "Loss:  126.8901 \n",
      "Output:  [ -0.3429, -17.2216, -10.6252,   9.8122] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  57000 \n",
      "Loss:  10.4503 \n",
      "Output:  [-0.4711, -2.8808, -2.8864, -4.2634] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  58000 \n",
      "Loss:  119.7970 \n",
      "Output:  [ 3.1609, 12.1265, 10.1053, 15.5975] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  59000 \n",
      "Loss:  302.8860 \n",
      "Output:  [  1.0226, -31.9403, -10.4211,  10.0396] \n",
      "Target:  [0., 0., 0., 1.]\n",
      "\n",
      "\n",
      "iteration:  60000 \n",
      "Loss:  894.7801 \n",
      "Output:  [-19.9925, -40.7753, -28.8097,  24.5813] \n",
      "Target:  [0., 1., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  61000 \n",
      "Loss:  12.3629 \n",
      "Output:  [-1.1708, -4.3605, -2.5661,  4.0435] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  62000 \n",
      "Loss:  13.8939 \n",
      "Output:  [-1.1618, -5.5016, -2.6896,  3.2163] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  63000 \n",
      "Loss:  6.8270 \n",
      "Output:  [-0.4033,  5.0270,  0.0828, -1.0166] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  64000 \n",
      "Loss:  134.4851 \n",
      "Output:  [  1.2208, -19.0522,  -8.0070,  10.5258] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  65000 \n",
      "Loss:  27.2638 \n",
      "Output:  [1.9653, 2.3557, 6.2786, 8.4723] \n",
      "Target:  [0., 0., 1., 0.]\n",
      "\n",
      "\n",
      "iteration:  66000 \n",
      "Loss:  125.7009 \n",
      "Output:  [ -4.1706, -16.8749,  -6.9792, -11.9414] \n",
      "Target:  [1., 0., 0., 0.]\n",
      "\n",
      "\n",
      "iteration:  67000 \n",
      "Loss:  11.3663 \n",
      "Output:  [-2.8182, -3.9456, -3.1540,  2.3175] \n",
      "Target:  [1., 0., 0., 0.]\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "while ((loss > 0.0005) and (lossDuplicationCounter<10)):\n",
    "    a=r(0, (len(contents)/15-1))\n",
    "    chars = torch.tensor(contents[(a*15):(a*15+14)])\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    out = net(chars)\n",
    "    if (contents[a*14+15]=='Marcin'):\n",
    "        target = torch.tensor([1., 0., 0., 0.])\n",
    "    elif (contents[a*14+15]=='Bartek'):\n",
    "        target = torch.tensor([0., 1., 0., 0.])\n",
    "    elif (contents[a*14+15]=='Maciek'):\n",
    "        target = torch.tensor([0., 0., 1., 0.,])\n",
    "    elif (contents[a*14+15]=='Artur'):\n",
    "        target = torch.tensor([0., 0., 0., 1.,])\n",
    "    loss = criterion(out, target)\n",
    "    if prevloss == loss:\n",
    "        lossDuplicationCounter +=1\n",
    "        print('loss duplicate #', lossDuplicationCounter)\n",
    "    else:\n",
    "        lossDuplicationCounter = 0\n",
    "    prevloss = loss\n",
    "    loss.backward(retain_graph=True)\n",
    "    #loss.backward()\n",
    "    optimizer.step()   # Does the update\n",
    "    if i%1000==0:\n",
    "        print(\"\\n\\niteration: \", i, \n",
    "              \"\\nLoss: \", ((str(loss)).strip('tensor()')).strip(', grad_fn=<MseLossBackward>) '), \n",
    "              '\\nOutput: ', ((str(out)).strip('tensor(')).strip(', grad_fn=<AddBackward0>)'),\n",
    "              '\\nTarget: ', str(target).strip('tensor(').strip(')'))\n",
    "    i+=1\n",
    "print(\"Learning time: \\n\\t\", time.time()-start)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\niteration: \", i, \n",
    "              \"\\nLoss: \", ((str(loss)).strip('tensor()')).strip(', grad_fn=<MseLossBackward>) '), \n",
    "              '\\nOutput: ', ((str(out)).strip('tensor(')).strip(', grad_fn=<AddBackward0>)'),\n",
    "              '\\nTarget: ', str(target).strip('tensor(').strip(')'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print\n",
    "i=0\n",
    "for filename in glob.glob(path):\n",
    "    #a=r(0, (len(contents)/15-1))\n",
    "    chars = torch.tensor(contents[(i*15):(i*15+14)])\n",
    "    #print(str(net(chars)).strip(\", grad_fn=<AddBackward0>)\").strip(\"tensor(\"), \"\\t : \",contents[i*15+14])\n",
    "    print(((str(net(chars))).strip('tensor(')).strip(', grad_fn=<AddBackward0>)'), \" : \", contents[i*15+14])\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in net.state_dict():\n",
    "    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, \"net.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "haba = torch.load(\"net.pt\")\n",
    "haba.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "i=0\n",
    "ilezg=0\n",
    "for filename in glob.glob(path):\n",
    "    tt=torch.tensor(contents[(a*15):(a*15+14)])\n",
    "    who = contents[i*15+14]\n",
    "    predykcja = haba(tt)\n",
    "    predlist = predykcja.tolist().index(max(predykcja.tolist()))\n",
    "    predykcjaOsoba=''\n",
    "    if predlist == 0:\n",
    "        predykcjaOsoba='Marcin'\n",
    "    elif predlist == 1:\n",
    "        predykcjaOsoba='Bartek'\n",
    "    elif predlist == 2:\n",
    "        predykcjaOsoba='Maciek'\n",
    "    elif predlist == 3:\n",
    "        predykcjaOsoba='Artur'\n",
    "    else:\n",
    "        print('ERROR!!!')\n",
    "    print(i, who, ' : \\n', str(tt).strip('tensor(').strip(')'), '\\n', str(predykcja).strip('tensor(').strip(', grad_fn=<AddBackward0>)'))\n",
    "    i+=1\n",
    "    if who == predykcjaOsoba:\n",
    "        ilezg+=1\n",
    "print(ilezg/i*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
